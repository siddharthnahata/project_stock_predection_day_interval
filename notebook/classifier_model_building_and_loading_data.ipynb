{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e401004",
   "metadata": {},
   "source": [
    "## **2. This notebook is for model testing and finding best code and model for Classification model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91b791",
   "metadata": {},
   "source": [
    "**Importing necessary library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bea4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import ta\n",
    "import concurrent.futures # for faster data fectching\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# all the necessary library for the model building and it's evaluations\n",
    "\n",
    "## evaluation function and objects\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, roc_auc_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "## data preprocessing function and objects\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "## model building and algorithms\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709e671",
   "metadata": {},
   "source": [
    "### **2.1 --> fetching data and looking data creating new feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2302af",
   "metadata": {},
   "source": [
    "#### 2.11 fetching data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e583296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function can be used when updating the model and in production model updating\n",
    "def data_fetch_feature_generation(ticker: str):\n",
    "    try:\n",
    "        t = yf.Ticker(ticker)\n",
    "\n",
    "        # Fetch price history\n",
    "        df = t.history(interval=\"1d\", period=\"5y\")\n",
    "        if df.empty:\n",
    "            print(f\"[WARN] No data for {ticker}\")\n",
    "            return None, None, None\n",
    "\n",
    "        df.index = df.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Technical indicators\n",
    "        df[\"return_1d\"] = df[\"Close\"].pct_change(1)\n",
    "        df[\"return_5d\"] = df[\"Close\"].pct_change(5)\n",
    "        df[\"return_10d\"] = df[\"Close\"].pct_change(10)\n",
    "        df['rsi'] = ta.momentum.RSIIndicator(df['Close']).rsi()\n",
    "        df['macd'] = ta.trend.MACD(df['Close']).macd()\n",
    "        df[\"stoch\"] = ta.momentum.StochasticOscillator(df[\"High\"], df[\"Low\"], df[\"Close\"]).stoch()\n",
    "        df[\"roc\"] = ta.momentum.ROCIndicator(df[\"Close\"]).roc()\n",
    "        df[\"williams_r\"] = ta.momentum.WilliamsRIndicator(df[\"High\"], df[\"Low\"], df[\"Close\"]).williams_r()\n",
    "        df[\"realized_vol_5\"] = df[\"return_1d\"].rolling(5).std()\n",
    "        df[\"rolling_std_5\"]  = df[\"Close\"].rolling(5).std()\n",
    "        df[\"rolling_skew_5\"] = df[\"Close\"].rolling(5).skew()\n",
    "        df[\"rolling_kurt_5\"] = df[\"Close\"].rolling(5).kurt()\n",
    "        df['sma5'] = df['Close'].rolling(5).mean()\n",
    "        df['sma10'] = df['Close'].rolling(10).mean()\n",
    "        df['sma20'] = df['Close'].rolling(20).mean()\n",
    "        df['sma50'] = df['Close'].rolling(50).mean()\n",
    "        df['sma100'] = df['Close'].rolling(100).mean()\n",
    "        df['sma200'] = df['Close'].rolling(200).mean()\n",
    "        df[\"obv\"] = ta.volume.OnBalanceVolumeIndicator(df[\"Close\"], df[\"Volume\"]).on_balance_volume()\n",
    "        df[\"vwap\"] = (df[\"Volume\"] * (df[\"High\"]+df[\"Low\"]+df[\"Close\"])/3).cumsum() / df[\"Volume\"].cumsum()\n",
    "        df[\"volume_change\"] = df[\"Volume\"].pct_change()\n",
    "\n",
    "        # Safe sector info\n",
    "        sector = t.info.get('sector', 'Unknown')\n",
    "        df['sector'] = sector\n",
    "\n",
    "        # Target (next-day return direction)\n",
    "        df['target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "\n",
    "        # Drop missing rows\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # Features & labels\n",
    "        X = df[['return_1d', 'return_5d', 'return_10d', 'stoch', 'roc', 'williams_r', 'realized_vol_5', 'rolling_std_5', 'rolling_skew_5', 'rolling_kurt_5', 'rsi','macd','sma5','Volume', 'sma10','sma20','sma50','sma100','sma200','sector', 'obv', 'vwap', 'volume_change']]\n",
    "        y = df['target']\n",
    "\n",
    "        return df, X, y\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed for {ticker}: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f351e3",
   "metadata": {},
   "source": [
    "#### 2.12 Defining ticker for which data is to be fetched (list of 1000+ ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9948f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_ns = [\n",
    "\"20MICRONS.NS\",\"21STCENMGM.NS\",\"360ONE.NS\",\"3IINFOLTD.NS\",\"3MINDIA.NS\",\"3PLAND.NS\",\"5PAISA.NS\",\"63MOONS.NS\",\"A2ZINFRA.NS\",\"AAATECH.NS\",\n",
    "\"AADHARHFC.NS\",\"AAKASH.NS\",\"AAREYDRUGS.NS\",\"AARON.NS\",\"AARTECH.NS\",\"AARTIDRUGS.NS\",\"AARTIIND.NS\",\"AARTIPHARM.NS\",\"AARTISURF.NS\",\"AARVEEDEN.NS\",\n",
    "\"AARVI.NS\",\"AAVAS.NS\",\"ABAN.NS\",\"ABB.NS\",\"ABBOTINDIA.NS\",\"ABCAPITAL.NS\",\"ABCOTS.NS\",\"ABDL.NS\",\"ABFRL.NS\",\"ABINFRA.NS\",\n",
    "\"ABLBL.NS\",\"ABMINTLLTD.NS\",\"ABREL.NS\",\"ABSLAMC.NS\",\"ACC.NS\",\"ACCELYA.NS\",\"ACCURACY.NS\",\"ACE.NS\",\"ACEINTEG.NS\",\"ACI.NS\",\n",
    "\"ACL.NS\",\"ACLGATI.NS\",\"ACMESOLAR.NS\",\"ACUTAAS.NS\",\"ADANIENSOL.NS\",\"ADANIENT.NS\",\"ADANIGREEN.NS\",\"ADANIPORTS.NS\",\"ADANIPOWER.NS\",\"ADFFOODS.NS\",\n",
    "\"ADL.NS\",\"ADOR.NS\",\"ADROITINFO.NS\",\"ADSL.NS\",\"ADVANIHOTR.NS\",\"ADVENZYMES.NS\",\"AEGISLOG.NS\",\"AEGISVOPAK.NS\",\"AEROENTER.NS\",\"AEROFLEX.NS\",\n",
    "\"AERONEU.NS\",\"AETHER.NS\",\"AFCONS.NS\",\"AFFLE.NS\",\"AFFORDABLE.NS\",\"AFIL.NS\",\"AFSL.NS\",\"AGARIND.NS\",\"AGARWALEYE.NS\",\"AGI.NS\",\n",
    "\"AGIIL.NS\",\"AGRITECH.NS\",\"AGROPHOS.NS\",\"AGSTRA.NS\",\"AHCL.NS\",\"AHLADA.NS\",\"AHLEAST.NS\",\"AHLUCONT.NS\",\"AIAENG.NS\",\"AIIL.NS\",\n",
    "\"AIRAN.NS\",\"AIROLAM.NS\",\"AJANTPHARM.NS\",\"AJAXENGG.NS\",\"AJMERA.NS\",\"AJOONI.NS\",\"AKASH.NS\",\"AKG.NS\",\"AKI.NS\",\"AKSHAR.NS\",\n",
    "\"AKSHARCHEM.NS\",\"AKSHOPTFBR.NS\",\"AKUMS.NS\",\"AKZOINDIA.NS\",\"ALANKIT.NS\",\"ALBERTDAVD.NS\",\"ALEMBICLTD.NS\",\"ALICON.NS\",\"ALIVUS.NS\",\"ALKALI.NS\",\n",
    "\"ALKEM.NS\",\"ALKYLAMINE.NS\",\"ALLCARGO.NS\",\"ALLDIGI.NS\",\"ALLTIME.NS\",\"ALMONDZ.NS\",\"ALOKINDS.NS\",\"ALPA.NS\",\"ALPHAGEO.NS\",\"ALPSINDUS.NS\",\n",
    "\"AMANTA.NS\",\"AMBER.NS\",\"AMBICAAGAR.NS\",\"AMBIKCO.NS\",\"AMBUJACEM.NS\",\"AMDIND.NS\",\"AMJLAND.NS\",\"AMNPLST.NS\",\"AMRUTANJAN.NS\",\"ANANDRATHI.NS\",\n",
    "\"ANANTRAJ.NS\",\"ANDHRAPAP.NS\",\"ANDHRSUGAR.NS\",\"ANGELONE.NS\",\"ANIKINDS.NS\",\"ANKITMETAL.NS\",\"ANMOL.NS\",\"ANSALAPI.NS\",\"ANTELOPUS.NS\",\"ANTGRAPHIC.NS\",\n",
    "\"ANTHEM.NS\",\"ANUHPHR.NS\",\"ANUP.NS\",\"ANURAS.NS\",\"APARINDS.NS\",\"APCL.NS\",\"APCOTEXIND.NS\",\"APEX.NS\",\"APLAPOLLO.NS\",\"APLLTD.NS\",\n",
    "\"APOLLO.NS\",\"APOLLOHOSP.NS\",\"APOLLOPIPE.NS\",\"APOLLOTYRE.NS\",\"APOLSINHOT.NS\",\"APTECHT.NS\",\"APTUS.NS\",\"ARCHIDPLY.NS\",\"ARCHIES.NS\",\"ARE&M.NS\",\n",
    "\"ARENTERP.NS\",\"ARFIN.NS\",\"ARIES.NS\",\"ARIHANTCAP.NS\",\"ARIHANTSUP.NS\",\"ARISINFRA.NS\",\"ARKADE.NS\",\"ARMANFIN.NS\",\"AROGRANITE.NS\",\"ARROWGREEN.NS\",\n",
    "\"ARSHIYA.NS\",\"ARTEMISMED.NS\",\"ARTNIRMAN.NS\",\"ARVEE.NS\",\"ARVIND.NS\",\"ARVINDFASN.NS\",\"ARVSMART.NS\",\"ASAHIINDIA.NS\",\"ASAHISONG.NS\",\"ASAL.NS\",\n",
    "\"ASALCBR.NS\",\"ASHAPURMIN.NS\",\"ASHIANA.NS\",\"ASHIMASYN.NS\",\"ASHOKA.NS\",\"ASHOKAMET.NS\",\"ASHOKLEY.NS\",\"ASIANENE.NS\",\"ASIANHOTNR.NS\",\"ASIANPAINT.NS\",\n",
    "\"ASIANTILES.NS\",\"ASKAUTOLTD.NS\",\"ASMS.NS\",\"ASPINWALL.NS\",\"ASTEC.NS\",\"ASTERDM.NS\",\"ASTRAL.NS\",\"ASTRAMICRO.NS\",\"ASTRAZEN.NS\",\"ASTRON.NS\",\n",
    "\"ATALREAL.NS\",\"ATAM.NS\",\"ATGL.NS\",\"ATHERENERG.NS\",\"ATL.NS\",\"ATLANTAA.NS\",\"ATLASCYCLE.NS\",\"ATUL.NS\",\"ATULAUTO.NS\",\"AUBANK.NS\",\n",
    "\"AURIONPRO.NS\",\"AUROPHARMA.NS\",\"AURUM.NS\",\"AUSOMENT.NS\",\"AUTOAXLES.NS\",\"AUTOIND.NS\",\"AVADHSUGAR.NS\",\"AVALON.NS\",\"AVANTEL.NS\",\"AVANTIFEED.NS\",\n",
    "\"AVG.NS\",\"AVL.NS\",\"AVONMORE.NS\",\"AVROIND.NS\",\"AVTNPL.NS\",\"AWFIS.NS\",\"AWHCL.NS\",\"AWL.NS\",\"AXISBANK.NS\",\"AXISCADES.NS\",\n",
    "\"AXITA.NS\",\"AYMSYNTEX.NS\",\"AZAD.NS\",\"BAFNAPH.NS\",\"BAGFILMS.NS\",\"BAIDFIN.NS\",\"BAJAJ-AUTO.NS\",\"BAJAJCON.NS\",\"BAJAJELEC.NS\",\"BAJAJFINSV.NS\",\n",
    "\"BAJAJHCARE.NS\",\"BAJAJHFL.NS\",\"BAJAJHIND.NS\",\"BAJAJHLDNG.NS\",\"BAJAJINDEF.NS\",\"BAJEL.NS\",\"BAJFINANCE.NS\",\"BALAJEE.NS\",\"BALAJITELE.NS\",\"BALAMINES.NS\",\n",
    "\"BALAXI.NS\",\"BALKRISHNA.NS\",\"BALKRISIND.NS\",\"BALMLAWRIE.NS\",\"BALPHARMA.NS\",\"BALRAMCHIN.NS\",\"BALUFORGE.NS\",\"BANARBEADS.NS\",\"BANARISUG.NS\",\"BANCOINDIA.NS\",\n",
    "\"BANDHANBNK.NS\",\"BANG.NS\",\"BANKA.NS\",\"BANKBARODA.NS\",\"BANKINDIA.NS\",\"BANSALWIRE.NS\",\"BANSWRAS.NS\",\"BARBEQUE.NS\",\"BASF.NS\",\"BASML.NS\",\n",
    "\"BATAINDIA.NS\",\"BAYERCROP.NS\",\"BBL.NS\",\"BBOX.NS\",\"BBTC.NS\",\"BBTCL.NS\",\"BCG.NS\",\"BCLIND.NS\",\"BCONCEPTS.NS\",\"BDL.NS\",\n",
    "\"BEARDSELL.NS\",\"BECTORFOOD.NS\",\"BEDMUTHA.NS\",\"BEL.NS\",\"BELLACASA.NS\",\"BELRISE.NS\",\"BEML.NS\",\"BEPL.NS\",\"BERGEPAINT.NS\",\"BESTAGRO.NS\"\n",
    "]\n",
    "tickers_ns += [\n",
    "\"BFINVEST.NS\",\"BFUTILITIE.NS\",\"BGRENERGY.NS\",\"BHAGCHEM.NS\",\"BHAGERIA.NS\",\"BHAGYANGR.NS\",\"BHANDARI.NS\",\"BHARATFORG.NS\",\"BHARATGEAR.NS\",\"BHARATRAS.NS\",\n",
    "\"BHARATSE.NS\",\"BHARATWIRE.NS\",\"BHARTIARTL.NS\",\"BHARTIHEXA.NS\",\"BHEL.NS\",\"BIGBLOC.NS\",\"BIKAJI.NS\",\"BIL.NS\",\"BILVYAPAR.NS\",\"BIOCON.NS\",\n",
    "\"BIOFILCHEM.NS\",\"BIRLACABLE.NS\",\"BIRLACORPN.NS\",\"BIRLAMONEY.NS\",\"BIRLANU.NS\",\"BLACKBUCK.NS\",\"BLAL.NS\",\"BLBLIMITED.NS\",\"BLISSGVS.NS\",\"BLKASHYAP.NS\",\n",
    "\"BLS.NS\",\"BLSE.NS\",\"BLUECOAST.NS\",\"BLUEDART.NS\",\"BLUEJET.NS\",\"BLUESTARCO.NS\",\"BLUESTONE.NS\",\"BLUSPRING.NS\",\"BODALCHEM.NS\",\"BOHRAIND.NS\",\n",
    "\"BOMDYEING.NS\",\"BORANA.NS\",\"BOROLTD.NS\",\"BORORENEW.NS\",\"BOROSCI.NS\",\"BOSCHLTD.NS\",\"BPCL.NS\",\"BPL.NS\",\"BRIGADE.NS\",\"BRIGHOTEL.NS\",\n",
    "\"BRITANNIA.NS\",\"BRNL.NS\",\"BROOKS.NS\",\"BSE.NS\",\"BSHSL.NS\",\"BSL.NS\",\"BSOFT.NS\",\"BTML.NS\",\"BUTTERFLY.NS\",\"BVCL.NS\",\n",
    "\"BYKE.NS\",\"CALSOFT.NS\",\"CAMLINFINE.NS\",\"CAMPUS.NS\",\"CAMS.NS\",\"CANBK.NS\",\"CANFINHOME.NS\",\"CANTABIL.NS\",\"CAPACITE.NS\",\"CAPITALSFB.NS\",\n",
    "\"CAPLIPOINT.NS\",\"CAPTRUST.NS\",\"CARBORUNIV.NS\",\"CARERATING.NS\",\"CARRARO.NS\",\"CARTRADE.NS\",\"CARYSIL.NS\",\"CASTROLIND.NS\",\"CCCL.NS\",\"CCHHL.NS\",\n",
    "\"CCL.NS\",\"CDSL.NS\",\"CEATLTD.NS\",\"CEIGALL.NS\",\"CELEBRITY.NS\",\"CELLO.NS\",\"CEMPRO.NS\",\"CENTENKA.NS\",\"CENTEXT.NS\",\"CENTRALBK.NS\",\n",
    "\"CENTRUM.NS\",\"CENTUM.NS\",\"CENTURYPLY.NS\",\"CERA.NS\",\"CEREBRAINT.NS\",\"CESC.NS\",\"CEWATER.NS\",\"CGCL.NS\",\"CGPOWER.NS\",\"CHALET.NS\",\n",
    "\"CHAMBLFERT.NS\",\"CHEMBOND.NS\",\"CHEMBONDCH.NS\",\"CHEMCON.NS\",\"CHEMFAB.NS\",\"CHEMPLASTS.NS\",\"CHENNPETRO.NS\",\"CHEVIOT.NS\",\"CHOICEIN.NS\",\"CHOLAFIN.NS\",\n",
    "\"CHOLAHLDNG.NS\",\"CIEINDIA.NS\",\"CIFL.NS\",\"CIGNITITEC.NS\",\"CINELINE.NS\",\"CINEVISTA.NS\",\"CIPLA.NS\",\"CLEAN.NS\",\"CLEDUCATE.NS\",\"CLSEL.NS\",\n",
    "\"CMSINFO.NS\",\"COALINDIA.NS\",\"COASTCORP.NS\",\"COCHINSHIP.NS\",\"COFFEEDAY.NS\",\"COFORGE.NS\",\"COHANCE.NS\",\"COLPAL.NS\",\"COMPINFO.NS\",\"COMPUSOFT.NS\",\n",
    "\"COMSYN.NS\",\"CONCOR.NS\",\"CONCORDBIO.NS\",\"CONFIPET.NS\",\"CONSOFINVT.NS\",\"CONTROLPR.NS\",\"CORALFINAC.NS\",\"CORDSCABLE.NS\",\"COROMANDEL.NS\",\"COSMOFIRST.NS\",\n",
    "\"COUNCODOS.NS\",\"CPCAP.NS\",\"CPEDU.NS\",\"CPPLUS.NS\",\"CRAFTSMAN.NS\",\"CREATIVE.NS\",\"CREATIVEYE.NS\",\"CREDITACC.NS\",\"CREST.NS\",\"CRISIL.NS\",\n",
    "\"CRIZAC.NS\",\"CROMPTON.NS\",\"CROWN.NS\",\"CSBBANK.NS\",\"CSLFINANCE.NS\",\"CTE.NS\",\"CUB.NS\",\"CUBEXTUB.NS\",\"CUMMINSIND.NS\",\"CUPID.NS\",\n",
    "\"CURAA.NS\",\"CYBERMEDIA.NS\",\"CYBERTECH.NS\",\"CYIENT.NS\",\"CYIENTDLM.NS\",\"DABUR.NS\",\"DALBHARAT.NS\",\"DALMIASUG.NS\",\"DAMCAPITAL.NS\",\"DAMODARIND.NS\",\n",
    "\"DANGEE.NS\",\"DATAMATICS.NS\",\"DATAPATTNS.NS\",\"DAVANGERE.NS\",\"DBCORP.NS\",\"DBEIL.NS\",\"DBL.NS\",\"DBOL.NS\",\"DBREALTY.NS\",\"DBSTOCKBRO.NS\",\n",
    "\"DCAL.NS\",\"DCBBANK.NS\",\"DCI.NS\",\"DCM.NS\",\"DCMFINSERV.NS\",\"DCMNVL.NS\",\"DCMSHRIRAM.NS\",\"DCMSRIND.NS\",\"DCW.NS\",\"DCXINDIA.NS\",\n",
    "\"DDEVPLSTIK.NS\",\"DECCANCE.NS\",\"DEEDEV.NS\",\"DEEPAKFERT.NS\",\"DEEPAKNTR.NS\",\"DEEPINDS.NS\",\"DELHIVERY.NS\",\"DELPHIFX.NS\",\"DELTACORP.NS\",\"DELTAMAGNT.NS\",\n",
    "\"DEN.NS\",\"DENORA.NS\",\"DENTA.NS\",\"DEVIT.NS\",\"DEVX.NS\",\"DEVYANI.NS\",\"DGCONTENT.NS\",\"DHAMPURSUG.NS\",\"DHANBANK.NS\",\"DHANI.NS\",\n",
    "\"DHANUKA.NS\",\"DHARAN.NS\",\"DHARMAJ.NS\",\"DHRUV.NS\",\"DHUNINV.NS\",\"DIACABS.NS\",\"DIAMINESQ.NS\",\"DIAMONDYD.NS\",\"DICIND.NS\",\"DIFFNKG.NS\",\n",
    "\"DIGIDRIVE.NS\",\"DIGISPICE.NS\",\"DIGITIDE.NS\",\"DIGJAMLMTD.NS\",\"DIL.NS\",\"DISHTV.NS\",\"DIVGIITTS.NS\",\"DIVISLAB.NS\",\"DIXON.NS\",\"DJML.NS\",\n",
    "\"DLF.NS\",\"DLINKINDIA.NS\",\"DMART.NS\",\"DMCC.NS\",\"DNAMEDIA.NS\",\"DODLA.NS\",\"DOLATALGO.NS\",\"DOLLAR.NS\",\"DOLPHIN.NS\",\"DOMS.NS\",\n",
    "\"DONEAR.NS\",\"DPABHUSHAN.NS\",\"DPSCLTD.NS\",\"DPWIRES.NS\",\"DRCSYSTEMS.NS\",\"DREAMFOLKS.NS\",\"DREDGECORP.NS\",\"DRREDDY.NS\",\"DSSL.NS\",\"DTIL.NS\",\n",
    "\"DUCON.NS\",\"DVL.NS\",\"DWARKESH.NS\",\"DYCL.NS\",\"DYNAMATECH.NS\",\"DYNPRO.NS\",\"E2E.NS\",\"EASEMYTRIP.NS\",\"EBGNG.NS\",\"ECLERX.NS\",\n",
    "\"ECOSMOBLTY.NS\",\"EDELWEISS.NS\",\"EFCIL.NS\",\"EICHERMOT.NS\",\"EIDPARRY.NS\",\"EIEL.NS\",\"EIFFL.NS\",\"EIHAHOTELS.NS\",\"EIHOTEL.NS\",\"EIMCOELECO.NS\",\n",
    "\"EKC.NS\",\"ELDEHSG.NS\",\"ELECON.NS\",\"ELECTCAST.NS\",\"ELECTHERM.NS\",\"ELGIEQUIP.NS\",\"ELGIRUBCO.NS\",\"ELIN.NS\",\"ELLEN.NS\",\"EMAMILTD.NS\",\n",
    "\"EMAMIPAP.NS\",\"EMAMIREAL.NS\",\"EMBDL.NS\",\"EMCURE.NS\",\"EMIL.NS\",\"EMKAY.NS\",\"EMMBI.NS\",\"EMSLIMITED.NS\",\"EMUDHRA.NS\",\"ENDURANCE.NS\",\n",
    "\"ENERGYDEV.NS\",\"ENGINERSIN.NS\",\"ENIL.NS\",\"ENRIN.NS\",\"ENTERO.NS\",\"EPACK.NS\",\"EPIGRAL.NS\",\"EPL.NS\",\"EQUIPPP.NS\",\"EQUITASBNK.NS\"\n",
    "]\n",
    "tickers_ns += [\n",
    "\"ERIS.NS\",\"ESABINDIA.NS\",\"ESAFSFB.NS\",\"ESCORTS.NS\",\"ESSARSHPNG.NS\",\"ESSENTIA.NS\",\"ESTER.NS\",\"ETERNAL.NS\",\"ETHOSLTD.NS\",\"EUREKAFORB.NS\",\n",
    "\"EUROBOND.NS\",\"EUROPRATIK.NS\",\"EUROTEXIND.NS\",\"EVEREADY.NS\",\"EVERESTIND.NS\",\"EXCEL.NS\",\"EXCELINDUS.NS\",\"EXICOM.NS\",\"EXIDEIND.NS\",\"EXPLEOSOL.NS\",\n",
    "\"EXXARO.NS\",\"FACT.NS\",\"FAIRCHEMOR.NS\",\"FAZE3Q.NS\",\"FCL.NS\",\"FCSSOFT.NS\",\"FDC.NS\",\"FEDERALBNK.NS\",\"FEDFINA.NS\",\"FEL.NS\",\n",
    "\"FELDVR.NS\",\"FIBERWEB.NS\",\"FIEMIND.NS\",\"FILATEX.NS\",\"FILATFASH.NS\",\"FINCABLES.NS\",\"FINEORG.NS\",\"FINOPB.NS\",\"FINPIPE.NS\",\"FIRSTCRY.NS\",\n",
    "\"FISCHER.NS\",\"FIVESTAR.NS\",\"FLAIR.NS\",\"FLEXITUFF.NS\",\"FLFL.NS\",\"FLUOROCHEM.NS\",\"FMGOETZE.NS\",\"FMNL.NS\",\"FOCUS.NS\",\"FOODSIN.NS\",\n",
    "\"FORCEMOT.NS\",\"FORTIS.NS\",\"FOSECOIND.NS\",\"FSC.NS\",\"FSL.NS\",\"FUSION.NS\",\"GABRIEL.NS\",\"GAEL.NS\",\"GAIL.NS\",\"GALAPREC.NS\",\n",
    "\"GALAXYSURF.NS\",\"GALLANTT.NS\",\"GANDHAR.NS\",\"GANDHITUBE.NS\",\"GANECOS.NS\",\"GANESHBE.NS\",\"GANESHHOU.NS\",\"GANGAFORGE.NS\",\"GANGESSECU.NS\",\"GARFIBRES.NS\",\n",
    "\"GARUDA.NS\",\"GATECH.NS\",\"GATECHDVR.NS\",\"GATEWAY.NS\",\"GAYAHWS.NS\",\"GCSL.NS\",\"GEECEE.NS\",\"GEEKAYWIRE.NS\",\"GEMAROMA.NS\",\"GENCON.NS\",\n",
    "\"GENESYS.NS\",\"GENUSPAPER.NS\",\"GENUSPOWER.NS\",\"GEOJITFSL.NS\",\"GESHIP.NS\",\"GFLLIMITED.NS\",\"GHCL.NS\",\"GHCLTEXTIL.NS\",\"GICHSGFIN.NS\",\"GICRE.NS\",\n",
    "\"GILLANDERS.NS\",\"GILLETTE.NS\",\"GINNIFILA.NS\",\"GIPCL.NS\",\"GKWLIMITED.NS\",\"GLAND.NS\",\"GLAXO.NS\",\"GLENMARK.NS\",\"GLFL.NS\",\"GLOBAL.NS\",\n",
    "\"GLOBALE.NS\",\"GLOBALVECT.NS\",\"GLOBE.NS\",\"GLOBECIVIL.NS\",\"GLOBUSSPR.NS\",\"GLOSTERLTD.NS\",\"GMBREW.NS\",\"GMDCLTD.NS\",\"GMMPFAUDLR.NS\",\"GMRAIRPORT.NS\",\n",
    "\"GMRP&UI.NS\",\"GNA.NS\",\"GNFC.NS\",\"GOACARBON.NS\",\"GOCLCORP.NS\",\"GOCOLORS.NS\",\"GODAVARIB.NS\",\"GODFRYPHLP.NS\",\"GODHA.NS\",\"GODIGIT.NS\",\n",
    "\"GODREJAGRO.NS\",\"GODREJCP.NS\",\"GODREJIND.NS\",\"GODREJPROP.NS\",\"GOENKA.NS\",\"GOKEX.NS\",\"GOKUL.NS\",\"GOKULAGRO.NS\",\"GOLDENTOBC.NS\",\"GOLDIAM.NS\",\n",
    "\"GOLDTECH.NS\",\"GOODLUCK.NS\",\"GOPAL.NS\",\"GOYALALUM.NS\",\"GPIL.NS\",\"GPPL.NS\",\"GPTHEALTH.NS\",\"GPTINFRA.NS\",\"GRANULES.NS\",\"GRAPHITE.NS\",\n",
    "\"GRASIM.NS\",\"GRAVITA.NS\",\"GREAVESCOT.NS\",\"GREENLAM.NS\",\"GREENPANEL.NS\",\"GREENPLY.NS\",\"GREENPOWER.NS\",\"GRINDWELL.NS\",\"GRINFRA.NS\",\"GRMOVER.NS\",\n",
    "\"GROBTEA.NS\",\"GRPLTD.NS\",\"GRSE.NS\",\"GRWRHITECH.NS\",\"GSFC.NS\",\"GSLSU.NS\",\"GSPL.NS\",\"GSS.NS\",\"GTECJAINX.NS\",\"GTL.NS\",\n",
    "\"GTLINFRA.NS\",\"GTPL.NS\",\"GUFICBIO.NS\",\"GUJALKALI.NS\",\"GUJAPOLLO.NS\",\"GUJGASLTD.NS\",\"GUJRAFFIA.NS\",\"GUJTHEM.NS\",\"GULFOILLUB.NS\",\"GULFPETRO.NS\",\n",
    "\"GULPOLY.NS\",\"GVKPIL.NS\",\"GVPIL.NS\",\"GVPTECH.NS\",\"GVT&D.NS\",\"HAL.NS\",\"HAPPSTMNDS.NS\",\"HAPPYFORGE.NS\",\"HARDWYN.NS\",\"HARIOMPIPE.NS\",\n",
    "\"HARRMALAYA.NS\",\"HARSHA.NS\",\"HATHWAY.NS\",\"HATSUN.NS\",\"HAVELLS.NS\",\"HAVISHA.NS\",\"HBLENGINE.NS\",\"HBSL.NS\",\"HCC.NS\",\"HCG.NS\",\n",
    "\"HCL-INSYS.NS\",\"HCLTECH.NS\",\"HDBFS.NS\",\"HDFCAMC.NS\",\"HDFCBANK.NS\",\"HDFCLIFE.NS\",\"HDIL.NS\",\"HEADSUP.NS\",\"HECPROJECT.NS\",\"HEG.NS\",\n",
    "\"HEIDELBERG.NS\",\"HEMIPROP.NS\",\"HERANBA.NS\",\"HERCULES.NS\",\"HERITGFOOD.NS\",\"HEROMOTOCO.NS\",\"HESTERBIO.NS\",\"HEUBACHIND.NS\",\"HEXATRADEX.NS\",\"HEXT.NS\",\n",
    "\"HFCL.NS\",\"HGINFRA.NS\",\"HGM.NS\",\"HGS.NS\",\"HIKAL.NS\",\"HILINFRA.NS\",\"HILTON.NS\",\"HIMATSEIDE.NS\",\"HINDALCO.NS\",\"HINDCOMPOS.NS\",\n",
    "\"HINDCON.NS\",\"HINDCOPPER.NS\",\"HINDMOTORS.NS\",\"HINDOILEXP.NS\",\"HINDPETRO.NS\",\"HINDUNILVR.NS\",\"HINDWAREAP.NS\",\"HINDZINC.NS\",\"HIRECT.NS\",\"HISARMETAL.NS\",\n",
    "\"HITECH.NS\",\"HITECHCORP.NS\",\"HITECHGEAR.NS\",\"HLEGLAS.NS\",\"HLVLTD.NS\",\"HMAAGRO.NS\",\"HMT.NS\",\"HMVL.NS\",\"HNDFDS.NS\",\"HOMEFIRST.NS\",\n",
    "\"HONASA.NS\",\"HONAUT.NS\",\"HONDAPOWER.NS\",\"HPAL.NS\",\"HPIL.NS\",\"HPL.NS\",\"HSCL.NS\",\"HTMEDIA.NS\",\"HUBTOWN.NS\",\"HUDCO.NS\",\n",
    "\"HUHTAMAKI.NS\",\"HYBRIDFIN.NS\",\"HYUNDAI.NS\",\"ICDSLTD.NS\",\"ICEMAKE.NS\",\"ICICIBANK.NS\",\"ICICIGI.NS\",\"ICICIPRULI.NS\",\"ICIL.NS\",\"ICRA.NS\",\n",
    "\"IDBI.NS\",\"IDEA.NS\",\"IDEAFORGE.NS\",\"IDFCFIRSTB.NS\",\"IEL.NS\",\"IEX.NS\",\"IFBAGRO.NS\",\"IFBIND.NS\",\"IFCI.NS\",\"IFGLEXPOR.NS\"\n",
    "]\n",
    "tickers_ns += [\n",
    "\"IGARASHI.NS\",\"IGCL.NS\",\"IGIL.NS\",\"IGL.NS\",\"IGPL.NS\",\"IIFL.NS\",\"IIFLCAPS.NS\",\"IITL.NS\",\"IKIO.NS\",\"IKS.NS\",\n",
    "\"IL&FSENGG.NS\",\"IL&FSTRANS.NS\",\"IMAGICAA.NS\",\"IMFA.NS\",\"IMPAL.NS\",\"IMPEXFERRO.NS\",\"INCREDIBLE.NS\",\"INDBANK.NS\",\"INDGN.NS\",\"INDHOTEL.NS\",\n",
    "\"INDIACEM.NS\",\"INDIAGLYCO.NS\",\"INDIAMART.NS\",\"INDIANB.NS\",\"INDIANCARD.NS\",\"INDIANHUME.NS\",\"INDIASHLTR.NS\",\"INDIGO.NS\",\"INDIGOPNTS.NS\",\"INDIQUBE.NS\",\n",
    "\"INDNIPPON.NS\",\"INDOAMIN.NS\",\"INDOBORAX.NS\",\"INDOCO.NS\",\"INDOFARM.NS\",\"INDORAMA.NS\",\"INDOSTAR.NS\",\"INDOTECH.NS\",\"INDOTHAI.NS\",\"INDOUS.NS\",\n",
    "\"INDOWIND.NS\",\"INDRAMEDCO.NS\",\"INDSWFTLAB.NS\",\"INDTERRAIN.NS\",\"INDUSINDBK.NS\",\"INDUSTOWER.NS\",\"INFIBEAM.NS\",\"INFOBEAN.NS\",\"INFOMEDIA.NS\",\"INFY.NS\",\n",
    "\"INGERRAND.NS\",\"INNOVACAP.NS\",\"INNOVANA.NS\",\"INOXGREEN.NS\",\"INOXINDIA.NS\",\"INOXWIND.NS\",\"INSECTICID.NS\",\"INSPIRISYS.NS\",\"INTELLECT.NS\",\"INTENTECH.NS\",\n",
    "\"INTERARCH.NS\",\"INTLCONV.NS\",\"INVENTURE.NS\",\"IOB.NS\",\"IOC.NS\",\"IOLCP.NS\",\"IONEXCHANG.NS\",\"IPCALAB.NS\",\"IPL.NS\",\"IRB.NS\",\n",
    "\"IRCON.NS\",\"IRCTC.NS\",\"IREDA.NS\",\"IRFC.NS\",\"IRIS.NS\",\"IRISDOREME.NS\",\"IRMENERGY.NS\",\"ISFT.NS\",\"ISGEC.NS\",\"ISHANCH.NS\",\n",
    "\"ITC.NS\",\"ITCHOTELS.NS\",\"ITDC.NS\",\"ITI.NS\",\"IVC.NS\",\"IVP.NS\",\"IXIGO.NS\",\"IZMO.NS\",\"J&KBANK.NS\",\"JAGRAN.NS\",\n",
    "\"JAGSNPHARM.NS\",\"JAIBALAJI.NS\",\"JAICORPLTD.NS\",\"JAIPURKURT.NS\",\"JAMNAAUTO.NS\",\"JASH.NS\",\"JAYAGROGN.NS\",\"JAYBARMARU.NS\",\"JAYNECOIND.NS\",\"JAYSREETEA.NS\",\n",
    "\"JBCHEPHARM.NS\",\"JBMA.NS\",\"JCHAC.NS\",\"JETFREIGHT.NS\",\"JGCHEM.NS\",\"JHS.NS\",\"JINDALPHOT.NS\",\"JINDALPOLY.NS\",\"JINDALSAW.NS\",\"JINDALSTEL.NS\",\n",
    "\"JINDRILL.NS\",\"JINDWORLD.NS\",\"JIOFIN.NS\",\"JISLDVREQS.NS\",\"JISLJALEQS.NS\",\"JITFINFRA.NS\",\"JKCEMENT.NS\",\"JKIL.NS\",\"JKLAKSHMI.NS\",\"JKPAPER.NS\",\n",
    "\"JKTYRE.NS\",\"JLHL.NS\",\"JMA.NS\",\"JMFINANCIL.NS\",\"JNKINDIA.NS\",\"JOCIL.NS\",\"JPOLYINVST.NS\",\"JPPOWER.NS\",\"JSFB.NS\",\"JSL.NS\",\n",
    "\"JSLL.NS\",\"JSWCEMENT.NS\",\"JSWENERGY.NS\",\"JSWHL.NS\",\"JSWINFRA.NS\",\"JSWSTEEL.NS\",\"JTEKTINDIA.NS\",\"JTLIND.NS\",\"JUBLCPL.NS\",\"JUBLFOOD.NS\",\n",
    "\"JUBLINGREA.NS\",\"JUBLPHARMA.NS\",\"JUNIPER.NS\",\"JUSTDIAL.NS\",\"JWL.NS\",\"JYOTHYLAB.NS\",\"JYOTICNC.NS\",\"JYOTISTRUC.NS\",\"KABRAEXTRU.NS\",\"KAJARIACER.NS\",\n",
    "\"KAKATCEM.NS\",\"KALAMANDIR.NS\",\"KALPATARU.NS\",\"KALYANI.NS\",\"KALYANIFRG.NS\",\"KALYANKJIL.NS\",\"KAMATHOTEL.NS\",\"KAMDHENU.NS\",\"KAMOPAINTS.NS\",\"KANANIIND.NS\",\n",
    "\"KANORICHEM.NS\",\"KANPRPLA.NS\",\"KANSAINER.NS\",\"KAPSTON.NS\",\"KARMAENG.NS\",\"KARURVYSYA.NS\",\"KAUSHALYA.NS\",\"KAVDEFENCE.NS\",\"KAYA.NS\",\"KAYNES.NS\",\n",
    "\"KCP.NS\",\"KCPSUGIND.NS\",\"KDDL.NS\",\"KEC.NS\",\"KECL.NS\",\"KEEPLEARN.NS\",\"KEI.NS\",\"KELLTONTEC.NS\",\"KERNEX.NS\",\"KESORAMIND.NS\",\n",
    "\"KEYFINSERV.NS\",\"KFINTECH.NS\",\"KHADIM.NS\",\"KHAICHEM.NS\",\"KHAITANLTD.NS\",\"KHANDSE.NS\",\"KICL.NS\",\"KILITCH.NS\",\"KIMS.NS\",\"KINGFA.NS\",\n",
    "\"KIOCL.NS\",\"KIRIINDUS.NS\",\"KIRLOSBROS.NS\",\"KIRLOSENG.NS\",\"KIRLOSIND.NS\",\"KIRLPNU.NS\",\"KITEX.NS\",\"KKCL.NS\",\"KMEW.NS\",\"KMSUGAR.NS\",\n",
    "\"KNRCON.NS\",\"KOHINOOR.NS\",\"KOKUYOCMLN.NS\",\"KOLTEPATIL.NS\",\"KOPRAN.NS\",\"KOTAKBANK.NS\",\"KOTARISUG.NS\",\"KOTHARIPET.NS\",\"KOTHARIPRO.NS\",\"KPEL.NS\",\n",
    "\"KPIGREEN.NS\",\"KPIL.NS\",\"KPITTECH.NS\",\"KPRMILL.NS\",\"KRBL.NS\",\"KREBSBIO.NS\",\"KRIDHANINF.NS\",\"KRISHANA.NS\",\"KRISHIVAL.NS\",\"KRITI.NS\",\n",
    "\"KRITIKA.NS\",\"KRITINUT.NS\",\"KRN.NS\",\"KRONOX.NS\",\"KROSS.NS\",\"KRSNAA.NS\",\"KRYSTAL.NS\",\"KSB.NS\",\"KSCL.NS\",\"KSHITIJPOL.NS\",\n",
    "\"KSL.NS\",\"KSOLVES.NS\",\"KTKBANK.NS\",\"KUANTUM.NS\",\"LAGNAM.NS\",\"LAL.NS\",\"LALPATHLAB.NS\",\"LAMBODHARA.NS\",\"LANCORHOL.NS\",\"LANDMARK.NS\",\n",
    "\"LAOPALA.NS\",\"LASA.NS\",\"LATENTVIEW.NS\",\"LATTEYS.NS\",\"LAURUSLABS.NS\",\"LAXMICOT.NS\",\"LAXMIDENTL.NS\",\"LAXMIINDIA.NS\",\"LCCINFOTEC.NS\",\"LEMONTREE.NS\",\n",
    "\"LEXUS.NS\",\"LFIC.NS\",\"LGBBROSLTD.NS\",\"LGHL.NS\",\"LIBAS.NS\",\"LIBERTSHOE.NS\",\"LICHSGFIN.NS\",\"LICI.NS\",\"LIKHITHA.NS\",\"LINC.NS\",\n",
    "\"LINCOLN.NS\",\"LINDEINDIA.NS\",\"LLOYDSENGG.NS\",\"LLOYDSENT.NS\",\"LLOYDSME.NS\",\"LMW.NS\",\"LODH...\",\"ZUARIIND.NS\",\"ZYDUSLIFE.NS\",\"ZYDUSWELL.NS\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d5474",
   "metadata": {},
   "source": [
    "#### 2.13 simple for loop to fetch data for all the tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29da62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for LODH...: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for LFIC.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"User is unable to access this feature - https://bit.ly/yahoo-finance-api-feedback\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"User is unable to access this feature - https://bit.ly/yahoo-finance-api-feedback\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for LIKHITHA.NS: argument of type 'NoneType' is not iterable\n",
      "[ERROR] Failed for LINCOLN.NS: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"User is unable to access this feature - https://bit.ly/yahoo-finance-api-feedback\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for LINC.NS: argument of type 'NoneType' is not iterable\n",
      "[ERROR] Failed for ZUARIIND.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"User is unable to access this feature - https://bit.ly/yahoo-finance-api-feedback\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for LINDEINDIA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for LLOYDSME.NS: argument of type 'NoneType' is not iterable\n",
      "[ERROR] Failed for LGBBROSLTD.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"User is unable to access this feature - https://bit.ly/yahoo-finance-api-feedback\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for ZYDUSLIFE.NS: argument of type 'NoneType' is not iterable\n",
      "[ERROR] Failed for ZYDUSWELL.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for LMW.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "1/1120 done\n",
      "2/1120 done\n",
      "3/1120 done\n",
      "4/1120 done\n",
      "5/1120 done\n",
      "6/1120 done\n",
      "7/1120 done\n",
      "8/1120 done\n",
      "9/1120 done\n",
      "10/1120 done\n",
      "11/1120 done\n",
      "12/1120 done\n",
      "13/1120 done\n",
      "14/1120 done\n",
      "15/1120 done\n",
      "16/1120 done\n",
      "17/1120 done\n",
      "18/1120 done\n",
      "19/1120 done\n",
      "20/1120 done\n",
      "21/1120 done\n",
      "22/1120 done\n",
      "23/1120 done\n",
      "24/1120 done\n",
      "25/1120 done\n",
      "26/1120 done\n",
      "27/1120 done\n",
      "28/1120 done\n",
      "29/1120 done\n",
      "30/1120 done\n",
      "31/1120 done\n",
      "32/1120 done\n",
      "33/1120 done\n",
      "34/1120 done\n",
      "35/1120 done\n",
      "36/1120 done\n",
      "37/1120 done\n",
      "38/1120 done\n",
      "39/1120 done\n",
      "40/1120 done\n",
      "41/1120 done\n",
      "42/1120 done\n",
      "43/1120 done\n",
      "44/1120 done\n",
      "45/1120 done\n",
      "46/1120 done\n",
      "47/1120 done\n",
      "48/1120 done\n",
      "49/1120 done\n",
      "50/1120 done\n",
      "51/1120 done\n",
      "52/1120 done\n",
      "53/1120 done\n",
      "54/1120 done\n",
      "55/1120 done\n",
      "56/1120 done\n",
      "57/1120 done\n",
      "58/1120 done\n",
      "59/1120 done\n",
      "60/1120 done\n",
      "61/1120 done\n",
      "62/1120 done\n",
      "63/1120 done\n",
      "64/1120 done\n",
      "65/1120 done\n",
      "66/1120 done\n",
      "67/1120 done\n",
      "68/1120 done\n",
      "69/1120 done\n",
      "70/1120 done\n",
      "71/1120 done\n",
      "72/1120 done\n",
      "73/1120 done\n",
      "74/1120 done\n",
      "75/1120 done\n",
      "76/1120 done\n",
      "77/1120 done\n",
      "78/1120 done\n",
      "79/1120 done\n",
      "80/1120 done\n",
      "81/1120 done\n",
      "82/1120 done\n",
      "83/1120 done\n",
      "84/1120 done\n",
      "85/1120 done\n",
      "86/1120 done\n",
      "87/1120 done\n",
      "88/1120 done\n",
      "89/1120 done\n",
      "90/1120 done\n",
      "91/1120 done\n",
      "92/1120 done\n",
      "93/1120 done\n",
      "94/1120 done\n",
      "95/1120 done\n",
      "96/1120 done\n",
      "97/1120 done\n",
      "98/1120 done\n",
      "99/1120 done\n",
      "100/1120 done\n",
      "101/1120 done\n",
      "102/1120 done\n",
      "103/1120 done\n",
      "104/1120 done\n",
      "105/1120 done\n",
      "106/1120 done\n",
      "107/1120 done\n",
      "108/1120 done\n",
      "109/1120 done\n",
      "110/1120 done\n",
      "111/1120 done\n",
      "112/1120 done\n",
      "113/1120 done\n",
      "114/1120 done\n",
      "115/1120 done\n",
      "116/1120 done\n",
      "117/1120 done\n",
      "118/1120 done\n",
      "119/1120 done\n",
      "120/1120 done\n",
      "121/1120 done\n",
      "122/1120 done\n",
      "123/1120 done\n",
      "124/1120 done\n",
      "125/1120 done\n",
      "126/1120 done\n",
      "127/1120 done\n",
      "128/1120 done\n",
      "129/1120 done\n",
      "130/1120 done\n",
      "131/1120 done\n",
      "132/1120 done\n",
      "133/1120 done\n",
      "134/1120 done\n",
      "135/1120 done\n",
      "136/1120 done\n",
      "137/1120 done\n",
      "138/1120 done\n",
      "139/1120 done\n",
      "140/1120 done\n",
      "141/1120 done\n",
      "142/1120 done\n",
      "143/1120 done\n",
      "144/1120 done\n",
      "145/1120 done\n",
      "146/1120 done\n",
      "147/1120 done\n",
      "148/1120 done\n",
      "149/1120 done\n",
      "150/1120 done\n",
      "151/1120 done\n",
      "152/1120 done\n",
      "153/1120 done\n",
      "154/1120 done\n",
      "155/1120 done\n",
      "156/1120 done\n",
      "157/1120 done\n",
      "158/1120 done\n",
      "159/1120 done\n",
      "160/1120 done\n",
      "161/1120 done\n",
      "162/1120 done\n",
      "163/1120 done\n",
      "164/1120 done\n",
      "165/1120 done\n",
      "166/1120 done\n",
      "167/1120 done\n",
      "168/1120 done\n",
      "169/1120 done\n",
      "170/1120 done\n",
      "171/1120 done\n",
      "172/1120 done\n",
      "173/1120 done\n",
      "174/1120 done\n",
      "175/1120 done\n",
      "176/1120 done\n",
      "177/1120 done\n",
      "178/1120 done\n",
      "179/1120 done\n",
      "180/1120 done\n",
      "181/1120 done\n",
      "182/1120 done\n",
      "183/1120 done\n",
      "184/1120 done\n",
      "185/1120 done\n",
      "186/1120 done\n",
      "187/1120 done\n",
      "188/1120 done\n",
      "189/1120 done\n",
      "190/1120 done\n",
      "191/1120 done\n",
      "192/1120 done\n",
      "193/1120 done\n",
      "194/1120 done\n",
      "195/1120 done\n",
      "196/1120 done\n",
      "197/1120 done\n",
      "198/1120 done\n",
      "199/1120 done\n",
      "200/1120 done\n",
      "201/1120 done\n",
      "202/1120 done\n",
      "203/1120 done\n",
      "204/1120 done\n",
      "205/1120 done\n",
      "206/1120 done\n",
      "207/1120 done\n",
      "208/1120 done\n",
      "209/1120 done\n",
      "210/1120 done\n",
      "211/1120 done\n",
      "212/1120 done\n",
      "213/1120 done\n",
      "214/1120 done\n",
      "215/1120 done\n",
      "216/1120 done\n",
      "217/1120 done\n",
      "218/1120 done\n",
      "219/1120 done\n",
      "220/1120 done\n",
      "221/1120 done\n",
      "222/1120 done\n",
      "223/1120 done\n",
      "224/1120 done\n",
      "225/1120 done\n",
      "226/1120 done\n",
      "227/1120 done\n",
      "228/1120 done\n",
      "229/1120 done\n",
      "230/1120 done\n",
      "231/1120 done\n",
      "232/1120 done\n",
      "233/1120 done\n",
      "234/1120 done\n",
      "235/1120 done\n",
      "236/1120 done\n",
      "237/1120 done\n",
      "238/1120 done\n",
      "239/1120 done\n",
      "240/1120 done\n",
      "241/1120 done\n",
      "242/1120 done\n",
      "243/1120 done\n",
      "244/1120 done\n",
      "245/1120 done\n",
      "246/1120 done\n",
      "247/1120 done\n",
      "248/1120 done\n",
      "249/1120 done\n",
      "250/1120 done\n",
      "251/1120 done\n",
      "252/1120 done\n",
      "253/1120 done\n",
      "254/1120 done\n",
      "255/1120 done\n",
      "256/1120 done\n",
      "257/1120 done\n",
      "258/1120 done\n",
      "259/1120 done\n",
      "260/1120 done\n",
      "261/1120 done\n",
      "262/1120 done\n",
      "263/1120 done\n",
      "264/1120 done\n",
      "265/1120 done\n",
      "266/1120 done\n",
      "267/1120 done\n",
      "268/1120 done\n",
      "269/1120 done\n",
      "270/1120 done\n",
      "271/1120 done\n",
      "272/1120 done\n",
      "273/1120 done\n",
      "274/1120 done\n",
      "275/1120 done\n",
      "276/1120 done\n",
      "277/1120 done\n",
      "278/1120 done\n",
      "279/1120 done\n",
      "280/1120 done\n",
      "281/1120 done\n",
      "282/1120 done\n",
      "283/1120 done\n",
      "284/1120 done\n",
      "285/1120 done\n",
      "286/1120 done\n",
      "287/1120 done\n",
      "288/1120 done\n",
      "289/1120 done\n",
      "290/1120 done\n",
      "291/1120 done\n",
      "292/1120 done\n",
      "293/1120 done\n",
      "294/1120 done\n",
      "295/1120 done\n",
      "296/1120 done\n",
      "297/1120 done\n",
      "298/1120 done\n",
      "299/1120 done\n",
      "300/1120 done\n",
      "301/1120 done\n",
      "302/1120 done\n",
      "303/1120 done\n",
      "304/1120 done\n",
      "305/1120 done\n",
      "306/1120 done\n",
      "307/1120 done\n",
      "308/1120 done\n",
      "309/1120 done\n",
      "310/1120 done\n",
      "311/1120 done\n",
      "312/1120 done\n",
      "313/1120 done\n",
      "314/1120 done\n",
      "315/1120 done\n",
      "316/1120 done\n",
      "317/1120 done\n",
      "318/1120 done\n",
      "319/1120 done\n",
      "320/1120 done\n",
      "321/1120 done\n",
      "322/1120 done\n",
      "323/1120 done\n",
      "324/1120 done\n",
      "325/1120 done\n",
      "326/1120 done\n",
      "327/1120 done\n",
      "328/1120 done\n",
      "329/1120 done\n",
      "330/1120 done\n",
      "331/1120 done\n",
      "332/1120 done\n",
      "333/1120 done\n",
      "334/1120 done\n",
      "335/1120 done\n",
      "336/1120 done\n",
      "337/1120 done\n",
      "338/1120 done\n",
      "339/1120 done\n",
      "340/1120 done\n",
      "341/1120 done\n",
      "342/1120 done\n",
      "343/1120 done\n",
      "344/1120 done\n",
      "345/1120 done\n",
      "346/1120 done\n",
      "347/1120 done\n",
      "348/1120 done\n",
      "349/1120 done\n",
      "350/1120 done\n",
      "351/1120 done\n",
      "352/1120 done\n",
      "353/1120 done\n",
      "354/1120 done\n",
      "355/1120 done\n",
      "356/1120 done\n",
      "357/1120 done\n",
      "358/1120 done\n",
      "359/1120 done\n",
      "360/1120 done\n",
      "361/1120 done\n",
      "362/1120 done\n",
      "363/1120 done\n",
      "364/1120 done\n",
      "365/1120 done\n",
      "366/1120 done\n",
      "367/1120 done\n",
      "368/1120 done\n",
      "369/1120 done\n",
      "370/1120 done\n",
      "371/1120 done\n",
      "372/1120 done\n",
      "373/1120 done\n",
      "374/1120 done\n",
      "375/1120 done\n",
      "376/1120 done\n",
      "377/1120 done\n",
      "378/1120 done\n",
      "379/1120 done\n",
      "380/1120 done\n",
      "381/1120 done\n",
      "382/1120 done\n",
      "383/1120 done\n",
      "384/1120 done\n",
      "385/1120 done\n",
      "386/1120 done\n",
      "387/1120 done\n",
      "388/1120 done\n",
      "389/1120 done\n",
      "390/1120 done\n",
      "391/1120 done\n",
      "392/1120 done\n",
      "393/1120 done\n",
      "394/1120 done\n",
      "395/1120 done\n",
      "396/1120 done\n",
      "397/1120 done\n",
      "398/1120 done\n",
      "399/1120 done\n",
      "400/1120 done\n",
      "401/1120 done\n",
      "402/1120 done\n",
      "403/1120 done\n",
      "404/1120 done\n",
      "405/1120 done\n",
      "406/1120 done\n",
      "407/1120 done\n",
      "408/1120 done\n",
      "409/1120 done\n",
      "410/1120 done\n",
      "411/1120 done\n",
      "412/1120 done\n",
      "413/1120 done\n",
      "414/1120 done\n",
      "415/1120 done\n",
      "416/1120 done\n",
      "417/1120 done\n",
      "418/1120 done\n",
      "419/1120 done\n",
      "420/1120 done\n",
      "421/1120 done\n",
      "422/1120 done\n",
      "423/1120 done\n",
      "424/1120 done\n",
      "425/1120 done\n",
      "426/1120 done\n",
      "427/1120 done\n",
      "428/1120 done\n",
      "429/1120 done\n",
      "430/1120 done\n",
      "431/1120 done\n",
      "432/1120 done\n",
      "433/1120 done\n",
      "434/1120 done\n",
      "435/1120 done\n",
      "436/1120 done\n",
      "437/1120 done\n",
      "438/1120 done\n",
      "439/1120 done\n",
      "440/1120 done\n",
      "441/1120 done\n",
      "442/1120 done\n",
      "443/1120 done\n",
      "444/1120 done\n",
      "445/1120 done\n",
      "446/1120 done\n",
      "447/1120 done\n",
      "448/1120 done\n",
      "449/1120 done\n",
      "450/1120 done\n",
      "451/1120 done\n",
      "452/1120 done\n",
      "453/1120 done\n",
      "454/1120 done\n",
      "455/1120 done\n",
      "456/1120 done\n",
      "457/1120 done\n",
      "458/1120 done\n",
      "459/1120 done\n",
      "460/1120 done\n",
      "461/1120 done\n",
      "462/1120 done\n",
      "463/1120 done\n",
      "464/1120 done\n",
      "465/1120 done\n",
      "466/1120 done\n",
      "467/1120 done\n",
      "468/1120 done\n",
      "469/1120 done\n",
      "470/1120 done\n",
      "471/1120 done\n",
      "472/1120 done\n",
      "473/1120 done\n",
      "474/1120 done\n",
      "475/1120 done\n",
      "476/1120 done\n",
      "477/1120 done\n",
      "478/1120 done\n",
      "479/1120 done\n",
      "480/1120 done\n",
      "481/1120 done\n",
      "482/1120 done\n",
      "483/1120 done\n",
      "484/1120 done\n",
      "485/1120 done\n",
      "486/1120 done\n",
      "487/1120 done\n",
      "488/1120 done\n",
      "489/1120 done\n",
      "490/1120 done\n",
      "491/1120 done\n",
      "492/1120 done\n",
      "493/1120 done\n",
      "494/1120 done\n",
      "495/1120 done\n",
      "496/1120 done\n",
      "497/1120 done\n",
      "498/1120 done\n",
      "499/1120 done\n",
      "500/1120 done\n",
      "501/1120 done\n",
      "502/1120 done\n",
      "503/1120 done\n",
      "504/1120 done\n",
      "505/1120 done\n",
      "506/1120 done\n",
      "507/1120 done\n",
      "508/1120 done\n",
      "509/1120 done\n",
      "510/1120 done\n",
      "511/1120 done\n",
      "512/1120 done\n",
      "513/1120 done\n",
      "514/1120 done\n",
      "515/1120 done\n",
      "516/1120 done\n",
      "517/1120 done\n",
      "518/1120 done\n",
      "519/1120 done\n",
      "520/1120 done\n",
      "521/1120 done\n",
      "522/1120 done\n",
      "523/1120 done\n",
      "524/1120 done\n",
      "525/1120 done\n",
      "526/1120 done\n",
      "527/1120 done\n",
      "528/1120 done\n",
      "529/1120 done\n",
      "530/1120 done\n",
      "531/1120 done\n",
      "532/1120 done\n",
      "533/1120 done\n",
      "534/1120 done\n",
      "535/1120 done\n",
      "536/1120 done\n",
      "537/1120 done\n",
      "538/1120 done\n",
      "539/1120 done\n",
      "540/1120 done\n",
      "541/1120 done\n",
      "542/1120 done\n",
      "543/1120 done\n",
      "544/1120 done\n",
      "545/1120 done\n",
      "546/1120 done\n",
      "547/1120 done\n",
      "548/1120 done\n",
      "549/1120 done\n",
      "550/1120 done\n",
      "551/1120 done\n",
      "552/1120 done\n",
      "553/1120 done\n",
      "554/1120 done\n",
      "555/1120 done\n",
      "556/1120 done\n",
      "557/1120 done\n",
      "558/1120 done\n",
      "559/1120 done\n",
      "560/1120 done\n",
      "561/1120 done\n",
      "562/1120 done\n",
      "563/1120 done\n",
      "564/1120 done\n",
      "565/1120 done\n",
      "566/1120 done\n",
      "567/1120 done\n",
      "568/1120 done\n",
      "569/1120 done\n",
      "570/1120 done\n",
      "571/1120 done\n",
      "572/1120 done\n",
      "573/1120 done\n",
      "574/1120 done\n",
      "575/1120 done\n",
      "576/1120 done\n",
      "577/1120 done\n",
      "578/1120 done\n",
      "579/1120 done\n",
      "580/1120 done\n",
      "581/1120 done\n",
      "582/1120 done\n",
      "583/1120 done\n",
      "584/1120 done\n",
      "585/1120 done\n",
      "586/1120 done\n",
      "587/1120 done\n",
      "588/1120 done\n",
      "589/1120 done\n",
      "590/1120 done\n",
      "591/1120 done\n",
      "592/1120 done\n",
      "593/1120 done\n",
      "594/1120 done\n",
      "595/1120 done\n",
      "596/1120 done\n",
      "597/1120 done\n",
      "598/1120 done\n",
      "599/1120 done\n",
      "600/1120 done\n",
      "601/1120 done\n",
      "602/1120 done\n",
      "603/1120 done\n",
      "604/1120 done\n",
      "605/1120 done\n",
      "606/1120 done\n",
      "607/1120 done\n",
      "608/1120 done\n",
      "609/1120 done\n",
      "610/1120 done\n",
      "611/1120 done\n",
      "612/1120 done\n",
      "613/1120 done\n",
      "614/1120 done\n",
      "615/1120 done\n",
      "616/1120 done\n",
      "617/1120 done\n",
      "618/1120 done\n",
      "619/1120 done\n",
      "620/1120 done\n",
      "621/1120 done\n",
      "622/1120 done\n",
      "623/1120 done\n",
      "624/1120 done\n",
      "625/1120 done\n",
      "626/1120 done\n",
      "627/1120 done\n",
      "628/1120 done\n",
      "629/1120 done\n",
      "630/1120 done\n",
      "631/1120 done\n",
      "632/1120 done\n",
      "633/1120 done\n",
      "634/1120 done\n",
      "635/1120 done\n",
      "636/1120 done\n",
      "637/1120 done\n",
      "638/1120 done\n",
      "639/1120 done\n",
      "640/1120 done\n",
      "641/1120 done\n",
      "642/1120 done\n",
      "643/1120 done\n",
      "644/1120 done\n",
      "645/1120 done\n",
      "646/1120 done\n",
      "647/1120 done\n",
      "648/1120 done\n",
      "649/1120 done\n",
      "650/1120 done\n",
      "651/1120 done\n",
      "652/1120 done\n",
      "653/1120 done\n",
      "654/1120 done\n",
      "655/1120 done\n",
      "656/1120 done\n",
      "657/1120 done\n",
      "658/1120 done\n",
      "659/1120 done\n",
      "660/1120 done\n",
      "661/1120 done\n",
      "662/1120 done\n",
      "663/1120 done\n",
      "664/1120 done\n",
      "665/1120 done\n",
      "666/1120 done\n",
      "667/1120 done\n",
      "668/1120 done\n",
      "669/1120 done\n",
      "670/1120 done\n",
      "671/1120 done\n",
      "672/1120 done\n",
      "673/1120 done\n",
      "674/1120 done\n",
      "675/1120 done\n",
      "676/1120 done\n",
      "677/1120 done\n",
      "678/1120 done\n",
      "679/1120 done\n",
      "680/1120 done\n",
      "681/1120 done\n",
      "682/1120 done\n",
      "683/1120 done\n",
      "684/1120 done\n",
      "685/1120 done\n",
      "686/1120 done\n",
      "687/1120 done\n",
      "688/1120 done\n",
      "689/1120 done\n",
      "690/1120 done\n",
      "691/1120 done\n",
      "692/1120 done\n",
      "693/1120 done\n",
      "694/1120 done\n",
      "695/1120 done\n",
      "696/1120 done\n",
      "697/1120 done\n",
      "698/1120 done\n",
      "699/1120 done\n",
      "700/1120 done\n",
      "701/1120 done\n",
      "702/1120 done\n",
      "703/1120 done\n",
      "704/1120 done\n",
      "705/1120 done\n",
      "706/1120 done\n",
      "707/1120 done\n",
      "708/1120 done\n",
      "709/1120 done\n",
      "710/1120 done\n",
      "711/1120 done\n",
      "712/1120 done\n",
      "713/1120 done\n",
      "714/1120 done\n",
      "715/1120 done\n",
      "716/1120 done\n",
      "717/1120 done\n",
      "718/1120 done\n",
      "719/1120 done\n",
      "720/1120 done\n",
      "721/1120 done\n",
      "722/1120 done\n",
      "723/1120 done\n",
      "724/1120 done\n",
      "725/1120 done\n",
      "726/1120 done\n",
      "727/1120 done\n",
      "728/1120 done\n",
      "729/1120 done\n",
      "730/1120 done\n",
      "731/1120 done\n",
      "732/1120 done\n",
      "733/1120 done\n",
      "734/1120 done\n",
      "735/1120 done\n",
      "736/1120 done\n",
      "737/1120 done\n",
      "738/1120 done\n",
      "739/1120 done\n",
      "740/1120 done\n",
      "741/1120 done\n",
      "742/1120 done\n",
      "743/1120 done\n",
      "744/1120 done\n",
      "745/1120 done\n",
      "746/1120 done\n",
      "747/1120 done\n",
      "748/1120 done\n",
      "749/1120 done\n",
      "750/1120 done\n",
      "751/1120 done\n",
      "752/1120 done\n",
      "753/1120 done\n",
      "754/1120 done\n",
      "755/1120 done\n",
      "756/1120 done\n",
      "757/1120 done\n",
      "758/1120 done\n",
      "759/1120 done\n",
      "760/1120 done\n",
      "761/1120 done\n",
      "762/1120 done\n",
      "763/1120 done\n",
      "764/1120 done\n",
      "765/1120 done\n",
      "766/1120 done\n",
      "767/1120 done\n",
      "768/1120 done\n",
      "769/1120 done\n",
      "770/1120 done\n",
      "771/1120 done\n",
      "772/1120 done\n",
      "773/1120 done\n",
      "774/1120 done\n",
      "775/1120 done\n",
      "776/1120 done\n",
      "777/1120 done\n",
      "778/1120 done\n",
      "779/1120 done\n",
      "780/1120 done\n",
      "781/1120 done\n",
      "782/1120 done\n",
      "783/1120 done\n",
      "784/1120 done\n",
      "785/1120 done\n",
      "786/1120 done\n",
      "787/1120 done\n",
      "788/1120 done\n",
      "789/1120 done\n",
      "790/1120 done\n",
      "791/1120 done\n",
      "792/1120 done\n",
      "793/1120 done\n",
      "794/1120 done\n",
      "795/1120 done\n",
      "796/1120 done\n",
      "797/1120 done\n",
      "798/1120 done\n",
      "799/1120 done\n",
      "800/1120 done\n",
      "801/1120 done\n",
      "802/1120 done\n",
      "803/1120 done\n",
      "804/1120 done\n",
      "805/1120 done\n",
      "806/1120 done\n",
      "807/1120 done\n",
      "808/1120 done\n",
      "809/1120 done\n",
      "810/1120 done\n",
      "811/1120 done\n",
      "812/1120 done\n",
      "813/1120 done\n",
      "814/1120 done\n",
      "815/1120 done\n",
      "816/1120 done\n",
      "817/1120 done\n",
      "818/1120 done\n",
      "819/1120 done\n",
      "820/1120 done\n",
      "821/1120 done\n",
      "822/1120 done\n",
      "823/1120 done\n",
      "824/1120 done\n",
      "825/1120 done\n",
      "826/1120 done\n",
      "827/1120 done\n",
      "828/1120 done\n",
      "829/1120 done\n",
      "830/1120 done\n",
      "831/1120 done\n",
      "832/1120 done\n",
      "833/1120 done\n",
      "834/1120 done\n",
      "835/1120 done\n",
      "836/1120 done\n",
      "837/1120 done\n",
      "838/1120 done\n",
      "839/1120 done\n",
      "840/1120 done\n",
      "841/1120 done\n",
      "842/1120 done\n",
      "843/1120 done\n",
      "844/1120 done\n",
      "845/1120 done\n",
      "846/1120 done\n",
      "847/1120 done\n",
      "848/1120 done\n",
      "849/1120 done\n",
      "850/1120 done\n",
      "851/1120 done\n",
      "852/1120 done\n",
      "853/1120 done\n",
      "854/1120 done\n",
      "855/1120 done\n",
      "856/1120 done\n",
      "857/1120 done\n",
      "858/1120 done\n",
      "859/1120 done\n",
      "860/1120 done\n",
      "861/1120 done\n",
      "862/1120 done\n",
      "863/1120 done\n",
      "864/1120 done\n",
      "865/1120 done\n",
      "866/1120 done\n",
      "867/1120 done\n",
      "868/1120 done\n",
      "869/1120 done\n",
      "870/1120 done\n",
      "871/1120 done\n",
      "872/1120 done\n",
      "873/1120 done\n",
      "874/1120 done\n",
      "875/1120 done\n",
      "876/1120 done\n",
      "877/1120 done\n",
      "878/1120 done\n",
      "879/1120 done\n",
      "880/1120 done\n",
      "881/1120 done\n",
      "882/1120 done\n",
      "883/1120 done\n",
      "884/1120 done\n",
      "885/1120 done\n",
      "886/1120 done\n",
      "887/1120 done\n",
      "888/1120 done\n",
      "889/1120 done\n",
      "890/1120 done\n",
      "891/1120 done\n",
      "892/1120 done\n",
      "893/1120 done\n",
      "894/1120 done\n",
      "895/1120 done\n",
      "896/1120 done\n",
      "897/1120 done\n",
      "898/1120 done\n",
      "899/1120 done\n",
      "900/1120 done\n",
      "901/1120 done\n",
      "902/1120 done\n",
      "903/1120 done\n",
      "904/1120 done\n",
      "905/1120 done\n",
      "906/1120 done\n",
      "907/1120 done\n",
      "908/1120 done\n",
      "909/1120 done\n",
      "910/1120 done\n",
      "911/1120 done\n",
      "912/1120 done\n",
      "913/1120 done\n",
      "914/1120 done\n",
      "915/1120 done\n",
      "916/1120 done\n",
      "917/1120 done\n",
      "918/1120 done\n",
      "919/1120 done\n",
      "920/1120 done\n",
      "921/1120 done\n",
      "922/1120 done\n",
      "923/1120 done\n",
      "924/1120 done\n",
      "925/1120 done\n",
      "926/1120 done\n",
      "927/1120 done\n",
      "928/1120 done\n",
      "929/1120 done\n",
      "930/1120 done\n",
      "931/1120 done\n",
      "932/1120 done\n",
      "933/1120 done\n",
      "934/1120 done\n",
      "935/1120 done\n",
      "936/1120 done\n",
      "937/1120 done\n",
      "938/1120 done\n",
      "939/1120 done\n",
      "940/1120 done\n",
      "941/1120 done\n",
      "942/1120 done\n",
      "943/1120 done\n",
      "944/1120 done\n",
      "945/1120 done\n",
      "946/1120 done\n",
      "947/1120 done\n",
      "948/1120 done\n",
      "949/1120 done\n",
      "950/1120 done\n",
      "951/1120 done\n",
      "952/1120 done\n",
      "953/1120 done\n",
      "954/1120 done\n",
      "955/1120 done\n",
      "956/1120 done\n",
      "957/1120 done\n",
      "958/1120 done\n",
      "959/1120 done\n",
      "960/1120 done\n",
      "961/1120 done\n",
      "962/1120 done\n",
      "963/1120 done\n",
      "964/1120 done\n",
      "965/1120 done\n",
      "966/1120 done\n",
      "967/1120 done\n",
      "968/1120 done\n",
      "969/1120 done\n",
      "970/1120 done\n",
      "971/1120 done\n",
      "972/1120 done\n",
      "973/1120 done\n",
      "974/1120 done\n",
      "975/1120 done\n",
      "976/1120 done\n",
      "977/1120 done\n",
      "978/1120 done\n",
      "979/1120 done\n",
      "980/1120 done\n",
      "981/1120 done\n",
      "982/1120 done\n",
      "983/1120 done\n",
      "984/1120 done\n",
      "985/1120 done\n",
      "986/1120 done\n",
      "987/1120 done\n",
      "988/1120 done\n",
      "989/1120 done\n",
      "990/1120 done\n",
      "991/1120 done\n",
      "992/1120 done\n",
      "993/1120 done\n",
      "994/1120 done\n",
      "995/1120 done\n",
      "996/1120 done\n",
      "997/1120 done\n",
      "998/1120 done\n",
      "999/1120 done\n",
      "1000/1120 done\n",
      "1001/1120 done\n",
      "1002/1120 done\n",
      "1003/1120 done\n",
      "1004/1120 done\n",
      "1005/1120 done\n",
      "1006/1120 done\n",
      "1007/1120 done\n",
      "1008/1120 done\n",
      "1009/1120 done\n",
      "1010/1120 done\n",
      "1011/1120 done\n",
      "1012/1120 done\n",
      "1013/1120 done\n",
      "1014/1120 done\n",
      "1015/1120 done\n",
      "1016/1120 done\n",
      "1017/1120 done\n",
      "1018/1120 done\n",
      "1019/1120 done\n",
      "1020/1120 done\n",
      "1021/1120 done\n",
      "1022/1120 done\n",
      "1023/1120 done\n",
      "1024/1120 done\n",
      "1025/1120 done\n",
      "1026/1120 done\n",
      "1027/1120 done\n",
      "1028/1120 done\n",
      "1029/1120 done\n",
      "1030/1120 done\n",
      "1031/1120 done\n",
      "1032/1120 done\n",
      "1033/1120 done\n",
      "1034/1120 done\n",
      "1035/1120 done\n",
      "1036/1120 done\n",
      "1037/1120 done\n",
      "1038/1120 done\n",
      "1039/1120 done\n",
      "1040/1120 done\n",
      "1041/1120 done\n",
      "1042/1120 done\n",
      "1043/1120 done\n",
      "1044/1120 done\n",
      "1045/1120 done\n",
      "1046/1120 done\n",
      "1047/1120 done\n",
      "1048/1120 done\n",
      "1049/1120 done\n",
      "1050/1120 done\n",
      "1051/1120 done\n",
      "1052/1120 done\n",
      "1053/1120 done\n",
      "1054/1120 done\n",
      "1055/1120 done\n",
      "1056/1120 done\n",
      "1057/1120 done\n",
      "1058/1120 done\n",
      "1059/1120 done\n",
      "1060/1120 done\n",
      "1061/1120 done\n",
      "1062/1120 done\n",
      "1063/1120 done\n",
      "1064/1120 done\n",
      "1065/1120 done\n",
      "1066/1120 done\n",
      "1067/1120 done\n",
      "1068/1120 done\n",
      "1069/1120 done\n",
      "1070/1120 done\n",
      "1071/1120 done\n",
      "1072/1120 done\n",
      "1073/1120 done\n",
      "1074/1120 done\n",
      "1075/1120 done\n",
      "1076/1120 done\n",
      "1077/1120 done\n",
      "1078/1120 done\n",
      "1079/1120 done\n",
      "1080/1120 done\n",
      "1081/1120 done\n",
      "1082/1120 done\n",
      "1083/1120 done\n",
      "1084/1120 done\n",
      "1085/1120 done\n",
      "1086/1120 done\n",
      "1087/1120 done\n",
      "1088/1120 done\n",
      "1089/1120 done\n",
      "1090/1120 done\n",
      "1091/1120 done\n",
      "1092/1120 done\n",
      "1093/1120 done\n",
      "1094/1120 done\n",
      "1095/1120 done\n",
      "1096/1120 done\n",
      "1097/1120 done\n",
      "1098/1120 done\n",
      "1099/1120 done\n",
      "1100/1120 done\n",
      "1101/1120 done\n",
      "1102/1120 skipped\n",
      "1103/1120 skipped\n",
      "1104/1120 done\n",
      "1105/1120 done\n",
      "1106/1120 done\n",
      "1107/1120 done\n",
      "1108/1120 done\n",
      "1109/1120 skipped\n",
      "1110/1120 skipped\n",
      "1111/1120 skipped\n",
      "1112/1120 skipped\n",
      "1113/1120 done\n",
      "1114/1120 done\n",
      "1115/1120 skipped\n",
      "1116/1120 skipped\n",
      "1117/1120 skipped\n",
      "1118/1120 skipped\n",
      "1119/1120 skipped\n",
      "1120/1120 skipped\n"
     ]
    }
   ],
   "source": [
    "main_base_df_list = []\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Worker wrapper for safe execution\n",
    "def safe_fetch(ticker):\n",
    "    try:\n",
    "        return data_fetch_feature_generation(ticker)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {ticker}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Run in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    results = list(executor.map(safe_fetch, tickers_ns))\n",
    "\n",
    "# Collect results\n",
    "for i, (df_fetch, X_fetch, y_fetch) in enumerate(results, start=1):\n",
    "    if df_fetch is None or X_fetch is None or y_fetch is None:\n",
    "        print(f\"{i}/{len(tickers_ns)} skipped\")\n",
    "        continue\n",
    "    main_base_df_list.append(df_fetch)\n",
    "    X_list.append(X_fetch)\n",
    "    y_list.append(y_fetch)\n",
    "    print(f\"{i}/{len(tickers_ns)} done\")\n",
    "\n",
    "# Concatenate once\n",
    "main_base_df = pd.concat(main_base_df_list, axis=0).reset_index(drop=True)\n",
    "X = pd.concat(X_list, axis=0).reset_index(drop=True)\n",
    "y = pd.concat(y_list, axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c51c869",
   "metadata": {},
   "source": [
    "#### Summary for above code cells\n",
    "* We first made a function that fetchs stock historical prices of stocks and creats more features.\n",
    "* The we difined a list containing 1000+ tickers listed on NSE.\n",
    "* THe using for loop and concurrent tool which fetchs all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfda0b",
   "metadata": {},
   "source": [
    "### **2.2 --> Model building for best to find algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198f2cd",
   "metadata": {},
   "source": [
    "#### 2.21 Segregating feature as num and cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521e89d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features :  ['sector']\n",
      "Numerical Features :  ['return_1d', 'return_5d', 'return_10d', 'stoch', 'roc', 'williams_r', 'realized_vol_5', 'rolling_std_5', 'rolling_skew_5', 'rolling_kurt_5', 'rsi', 'macd', 'sma5', 'Volume', 'sma10', 'sma20', 'sma50', 'sma100', 'sma200', 'obv', 'vwap', 'volume_change']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "num_cols = []\n",
    "for i in X.columns:\n",
    "    if X[i].dtype == \"O\":\n",
    "        cat_cols.append(i)\n",
    "    else:\n",
    "        num_cols.append(i)\n",
    "print(\"Categorical Features : \", cat_cols)\n",
    "print(\"Numerical Features : \", num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce705d",
   "metadata": {},
   "source": [
    "#### Feature Summary\n",
    "\n",
    "- **Categorical Features**  \n",
    "  - `sector`: Represents the industry/sector classification of the stock.  \n",
    "\n",
    "- **Numerical Features**  \n",
    "  - `return_1d`: Daily return of the stock.  \n",
    "  - `return_5d`: Return over the last 5 days.  \n",
    "  - `return_10d`: Return over the last 10 days.  \n",
    "  - `stoch`: Stochastic oscillator value, measures momentum.  \n",
    "  - `roc`: Rate of Change, shows percentage change over a period.  \n",
    "  - `williams_r`: Williams %R, momentum indicator for overbought/oversold conditions.  \n",
    "  - `realized_vol_5`: Realized volatility over the last 5 days.  \n",
    "  - `rolling_std_5`: Rolling standard deviation (5-day window).  \n",
    "  - `rolling_skew_5`: Rolling skewness (5-day window).  \n",
    "  - `rolling_kurt_5`: Rolling kurtosis (5-day window).  \n",
    "  - `rsi`: Relative Strength Index, momentum-based indicator.  \n",
    "  - `macd`: Moving Average Convergence Divergence, trend/momentum indicator.  \n",
    "  - `sma5`: Simple Moving Average (5-day).  \n",
    "  - `Volume`: Trading volume of the stock.  \n",
    "  - `sma10`: Simple Moving Average (10-day).  \n",
    "  - `sma20`: Simple Moving Average (20-day).  \n",
    "  - `sma50`: Simple Moving Average (50-day).  \n",
    "  - `sma100`: Simple Moving Average (100-day).  \n",
    "  - `sma200`: Simple Moving Average (200-day).  \n",
    "  - `obv`: On-Balance Volume, combines price and volume for trend signals.  \n",
    "  - `vwap`: Volume Weighted Average Price.  \n",
    "  - `volume_change`: Change in trading volume compared to previous periods.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1c5af",
   "metadata": {},
   "source": [
    "#### 2.22 building models without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c15acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X, y, num_cols, cat_cols, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Train multiple classification models with preprocessing pipeline\n",
    "    and print accuracy + classification report for each.\n",
    "    \"\"\"\n",
    "    # Numeric columns\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.dropna()   # drop rows where any feature is NaN (was inf before)\n",
    "\n",
    "    # Also align y with X (important!)\n",
    "    y = y.loc[X.index]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), num_cols),\n",
    "            (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "        \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "        \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=random_state),\n",
    "        \"LightGBM\": LGBMClassifier(random_state=random_state),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "    }\n",
    "\n",
    "    # Train & evaluate\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", model)\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        print(f\"\\n====== {name} ======\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c09562a",
   "metadata": {},
   "source": [
    "#### Function Summary: `train_and_evaluate_models`\n",
    "\n",
    "- **Purpose**  \n",
    "  - Trains multiple classification models on given dataset.  \n",
    "  - Handles preprocessing for numerical and categorical features.  \n",
    "  - Evaluates models using accuracy and classification report.  \n",
    "\n",
    "- **Preprocessing Steps**  \n",
    "  - Replace infinite values (`inf`, `-inf`) with NaN.  \n",
    "  - Drop rows with missing values.  \n",
    "  - Align target `y` with filtered features `X`.  \n",
    "  - Split data into train and test sets (stratified).  \n",
    "  - Scale numerical features using `StandardScaler`.  \n",
    "  - Encode categorical features using `OrdinalEncoder` with unknown handling.  \n",
    "\n",
    "- **Models Trained**  \n",
    "  - Logistic Regression  \n",
    "  - Decision Tree Classifier  \n",
    "  - Gaussian Naive Bayes  \n",
    "  - AdaBoost Classifier  \n",
    "  - XGBoost Classifier  \n",
    "  - LightGBM Classifier  \n",
    "  - CatBoost Classifier  \n",
    "\n",
    "- **Evaluation Output**  \n",
    "  - For each model, prints:  \n",
    "    - Model name  \n",
    "    - Accuracy score on test data  \n",
    "    - Detailed classification report (precision, recall, F1-score, support)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154f44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Logistic Regression ======\n",
      "Accuracy: 0.533659151820905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69     98205\n",
      "           1       0.50      0.02      0.04     85742\n",
      "\n",
      "    accuracy                           0.53    183947\n",
      "   macro avg       0.51      0.50      0.37    183947\n",
      "weighted avg       0.52      0.53      0.39    183947\n",
      "\n",
      "\n",
      "====== DecisionTreeClassifier ======\n",
      "Accuracy: 0.5172250702648046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55     98205\n",
      "           1       0.48      0.49      0.48     85742\n",
      "\n",
      "    accuracy                           0.52    183947\n",
      "   macro avg       0.52      0.52      0.52    183947\n",
      "weighted avg       0.52      0.52      0.52    183947\n",
      "\n",
      "\n",
      "====== GaussianNB ======\n",
      "Accuracy: 0.4699723289860666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.19      0.28     98205\n",
      "           1       0.46      0.79      0.58     85742\n",
      "\n",
      "    accuracy                           0.47    183947\n",
      "   macro avg       0.48      0.49      0.43    183947\n",
      "weighted avg       0.49      0.47      0.42    183947\n",
      "\n",
      "\n",
      "====== AdaBoostClassifier ======\n",
      "Accuracy: 0.543662033085617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.69     98205\n",
      "           1       0.57      0.09      0.15     85742\n",
      "\n",
      "    accuracy                           0.54    183947\n",
      "   macro avg       0.56      0.51      0.42    183947\n",
      "weighted avg       0.55      0.54      0.44    183947\n",
      "\n",
      "\n",
      "====== XGBoost ======\n",
      "Accuracy: 0.5598025518219922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.80      0.66     98205\n",
      "           1       0.55      0.28      0.37     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.56      0.54      0.52    183947\n",
      "weighted avg       0.56      0.56      0.53    183947\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 342965, number of negative: 392820\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.495455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5623\n",
      "[LightGBM] [Info] Number of data points in the train set: 735785, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466121 -> initscore=-0.135723\n",
      "[LightGBM] [Info] Start training from score -0.135723\n",
      "\n",
      "====== LightGBM ======\n",
      "Accuracy: 0.5591664990459209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.87      0.68     98205\n",
      "           1       0.58      0.21      0.30     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.57      0.54      0.49    183947\n",
      "weighted avg       0.57      0.56      0.50    183947\n",
      "\n",
      "\n",
      "====== CatBoost ======\n",
      "Accuracy: 0.5612540568750781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.78      0.65     98205\n",
      "           1       0.55      0.31      0.40     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.56      0.55      0.53    183947\n",
      "weighted avg       0.56      0.56      0.54    183947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_models(X, y, num_cols, cat_cols) # trigger the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb040da4",
   "metadata": {},
   "source": [
    "#### Model Evaluation Summary\n",
    "\n",
    "- **Logistic Regression**\n",
    "  - Accuracy: **0.53**\n",
    "  - Class 0: High recall (0.98), but Class 1 recall is very poor (0.02).\n",
    "  - Imbalanced performance, favors majority class.\n",
    "\n",
    "- **Decision Tree Classifier**\n",
    "  - Accuracy: **0.52**\n",
    "  - Balanced precision/recall for both classes (~0.5).\n",
    "  - No strong advantage over baseline.\n",
    "\n",
    "- **Gaussian Naive Bayes**\n",
    "  - Accuracy: **0.47**\n",
    "  - Class 1 recall is decent (0.79), but Class 0 recall is very poor (0.19).\n",
    "  - Produces unbalanced predictions.\n",
    "\n",
    "- **AdaBoost Classifier**\n",
    "  - Accuracy: **0.54**\n",
    "  - Good recall for Class 0 (0.94), but weak recall for Class 1 (0.09).\n",
    "  - Skews toward majority class.\n",
    "\n",
    "- **XGBoost**\n",
    "  - Accuracy: **0.56**\n",
    "  - Better balance: Class 0 recall (0.80), Class 1 recall (0.28).\n",
    "  - Improved overall f1-scores compared to simpler models.\n",
    "\n",
    "- **LightGBM**\n",
    "  - Accuracy: **0.56**\n",
    "  - Strong Class 0 recall (0.87), weak Class 1 recall (0.21).\n",
    "  - Skewed toward negative class but slightly better than AdaBoost.\n",
    "\n",
    "- **CatBoost**\n",
    "  - Accuracy: **0.56**\n",
    "  - Class 0 recall (0.78), Class 1 recall (0.31).\n",
    "  - More balanced than LightGBM and AdaBoost.\n",
    "\n",
    "---\n",
    "\n",
    "**Overall Insights**  \n",
    "- Tree-based boosting models (**XGBoost, LightGBM, CatBoost**) perform best (~0.56 accuracy).  \n",
    "- Simpler models (**Logistic Regression, Decision Tree, GaussianNB**) show weaker balance between classes.  \n",
    "- Class imbalance is a major issue — models tend to favor Class 0 heavily.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a37ed",
   "metadata": {},
   "source": [
    "### **2.3 --> Hyper Tuning the Model will be very expensive so we will try stacking for best Model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67be70a",
   "metadata": {},
   "source": [
    "#### 2.31 Splitting data in training and test data and handling nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "362ebda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.dropna()   # drop rows where any feature is NaN (was inf before)\n",
    "\n",
    "# Also align y with X (important!)\n",
    "y = y.loc[X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fa7ec",
   "metadata": {},
   "source": [
    "#### 2.32 We will be Stacking CatBosst, LightGBM and XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "937e9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 342965, number of negative: 392820\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5623\n",
      "[LightGBM] [Info] Number of data points in the train set: 735785, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466121 -> initscore=-0.135723\n",
      "[LightGBM] [Info] Start training from score -0.135723\n",
      "[LightGBM] [Info] Number of positive: 274372, number of negative: 314256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5623\n",
      "[LightGBM] [Info] Number of data points in the train set: 588628, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466121 -> initscore=-0.135723\n",
      "[LightGBM] [Info] Start training from score -0.135723\n",
      "[LightGBM] [Info] Number of positive: 274372, number of negative: 314256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.354782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5623\n",
      "[LightGBM] [Info] Number of data points in the train set: 588628, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466121 -> initscore=-0.135723\n",
      "[LightGBM] [Info] Start training from score -0.135723\n",
      "[LightGBM] [Info] Number of positive: 274372, number of negative: 314256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5623\n",
      "[LightGBM] [Info] Number of data points in the train set: 588628, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466121 -> initscore=-0.135723\n",
      "[LightGBM] [Info] Start training from score -0.135723\n",
      "[LightGBM] [Info] Number of positive: 274372, number of negative: 314256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.195814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5623\n",
      "[LightGBM] [Info] Number of data points in the train set: 588628, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466121 -> initscore=-0.135723\n",
      "[LightGBM] [Info] Start training from score -0.135723\n",
      "[LightGBM] [Info] Number of positive: 274372, number of negative: 314256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5623\n",
      "[LightGBM] [Info] Number of data points in the train set: 588628, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466121 -> initscore=-0.135723\n",
      "[LightGBM] [Info] Start training from score -0.135723\n",
      "Stacked Model Accuracy: 0.562210854213442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.80      0.66     98205\n",
      "           1       0.56      0.29      0.38     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.56      0.54      0.52    183947\n",
      "weighted avg       0.56      0.56      0.53    183947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def stack_models(X, y, num_cols, cat_cols, test_size=0.2, random_state=42):\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), num_cols),\n",
    "            (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Base models\n",
    "    base_models = [\n",
    "        (\"xgb\", XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=random_state)),\n",
    "        (\"lgbm\", LGBMClassifier(random_state=random_state)),\n",
    "        (\"cat\", CatBoostClassifier(verbose=0, random_state=random_state))\n",
    "    ]\n",
    "\n",
    "    # Meta-model\n",
    "    meta_model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    # Stacking Classifier\n",
    "    clf = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"stack\", StackingClassifier(\n",
    "            estimators=base_models,\n",
    "            final_estimator=meta_model,\n",
    "            cv=5\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Fit and predict\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"Stacked Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return clf\n",
    "\n",
    "stacking_clf = stack_models(X,y, num_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42b715",
   "metadata": {},
   "source": [
    "#### Stacked Model Evaluation Summary\n",
    "\n",
    "- **Accuracy:** 0.56  \n",
    "- **Class 0 (Majority Class):**\n",
    "  - Precision: 0.56  \n",
    "  - Recall: 0.80 (good at detecting Class 0)  \n",
    "  - F1-score: 0.66  \n",
    "\n",
    "- **Class 1 (Minority Class):**\n",
    "  - Precision: 0.56  \n",
    "  - Recall: 0.29 (poor detection of Class 1)  \n",
    "  - F1-score: 0.38  \n",
    "\n",
    "- **Overall Performance:**\n",
    "  - Macro Avg F1: 0.52 → balanced but modest performance.  \n",
    "  - Weighted Avg F1: 0.53 → slightly favors majority class.  \n",
    "  - Stacking improves stability but class imbalance remains an issue.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f0780",
   "metadata": {},
   "source": [
    "#### 2.33 We have got 0.56 accuracy we will try modified y_pred_proba to improve accuracy mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7385a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5829\n",
      "Best Threshold: 0.4700\n",
      "Accuracy: 0.5577856665235095\n",
      "F1 Score: 0.5180585837520144\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "y_proba = stacking_clf.predict_proba(X_test)[:, 1]  # prob for class=1\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Find best cutoff (Youden’s J statistic = maximize TPR - FPR)\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"Best Threshold: {best_thresh:.4f}\")\n",
    "\n",
    "# Apply threshold\n",
    "y_pred_opt = (y_proba >= best_thresh).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_opt))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_opt))\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.scatter(fpr[ix], tpr[ix], marker='o', color='red', label=\"Best threshold\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve (AUC={roc_auc:.4f})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbfec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.47003292471115604\n",
      "Accuracy: 0.5577856665235095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59     98205\n",
      "           1       0.53      0.51      0.52     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.56      0.55      0.55    183947\n",
      "weighted avg       0.56      0.56      0.56    183947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_with_threshold(model, X_test, y_test, threshold=best_thresh):\n",
    "    # Get probabilities for class 1\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Apply threshold\n",
    "    y_pred = np.where(proba >= threshold, 1, 0)\n",
    "\n",
    "    # Metrics\n",
    "    print(f\"Threshold = {threshold}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "predict_with_threshold(stacking_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87a168",
   "metadata": {},
   "source": [
    "#### precision is low for class 1, lets try to achive above 0.6 with recall of +0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc07d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.4\n",
      "Accuracy: 0.5086519486591247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.17      0.26     98205\n",
      "           1       0.49      0.90      0.63     85742\n",
      "\n",
      "    accuracy                           0.51    183947\n",
      "   macro avg       0.57      0.53      0.45    183947\n",
      "weighted avg       0.58      0.51      0.44    183947\n",
      "\n",
      "Threshold = 0.42000000000000004\n",
      "Accuracy: 0.5215415309844683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.24      0.35     98205\n",
      "           1       0.49      0.84      0.62     85742\n",
      "\n",
      "    accuracy                           0.52    183947\n",
      "   macro avg       0.56      0.54      0.49    183947\n",
      "weighted avg       0.57      0.52      0.48    183947\n",
      "\n",
      "Threshold = 0.44000000000000006\n",
      "Accuracy: 0.536627398109238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.36      0.45     98205\n",
      "           1       0.50      0.74      0.60     85742\n",
      "\n",
      "    accuracy                           0.54    183947\n",
      "   macro avg       0.56      0.55      0.53    183947\n",
      "weighted avg       0.56      0.54      0.52    183947\n",
      "\n",
      "Threshold = 0.4600000000000001\n",
      "Accuracy: 0.5511152668975303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.55     98205\n",
      "           1       0.52      0.59      0.55     85742\n",
      "\n",
      "    accuracy                           0.55    183947\n",
      "   macro avg       0.55      0.55      0.55    183947\n",
      "weighted avg       0.56      0.55      0.55    183947\n",
      "\n",
      "Threshold = 0.4800000000000001\n",
      "Accuracy: 0.5610855300711618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.62     98205\n",
      "           1       0.54      0.43      0.48     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.56      0.55      0.55    183947\n",
      "weighted avg       0.56      0.56      0.55    183947\n",
      "\n",
      "Threshold = 0.5000000000000001\n",
      "Accuracy: 0.562210854213442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.80      0.66     98205\n",
      "           1       0.56      0.29      0.38     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.56      0.54      0.52    183947\n",
      "weighted avg       0.56      0.56      0.53    183947\n",
      "\n",
      "Threshold = 0.5200000000000001\n",
      "Accuracy: 0.5616019831799377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.68     98205\n",
      "           1       0.59      0.19      0.29     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.57      0.54      0.49    183947\n",
      "weighted avg       0.57      0.56      0.50    183947\n",
      "\n",
      "Threshold = 0.5400000000000001\n",
      "Accuracy: 0.5589925358934911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.93      0.69     98205\n",
      "           1       0.63      0.13      0.22     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.59      0.53      0.46    183947\n",
      "weighted avg       0.59      0.56      0.47    183947\n",
      "\n",
      "Threshold = 0.5600000000000002\n",
      "Accuracy: 0.5570898139137904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.70     98205\n",
      "           1       0.66      0.10      0.18     85742\n",
      "\n",
      "    accuracy                           0.56    183947\n",
      "   macro avg       0.61      0.53      0.44    183947\n",
      "weighted avg       0.60      0.56      0.45    183947\n",
      "\n",
      "Threshold = 0.5800000000000002\n",
      "Accuracy: 0.5548065475381496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70     98205\n",
      "           1       0.69      0.08      0.15     85742\n",
      "\n",
      "    accuracy                           0.55    183947\n",
      "   macro avg       0.62      0.52      0.42    183947\n",
      "weighted avg       0.61      0.55      0.44    183947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate values from 0.40 up to (but not including) 0.61, with a step of 0.2\n",
    "thresholds_values = np.arange(0.40, 0.60, 0.02)\n",
    "\n",
    "for thres in thresholds_values:\n",
    "    predict_with_threshold(stacking_clf, X_test, y_test, threshold=thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22072a36",
   "metadata": {},
   "source": [
    "#### Threshold Tuning Summary\n",
    "\n",
    "- **Threshold = 0.40**\n",
    "  - Accuracy: 0.51  \n",
    "  - Class 0 → Precision: 0.66, Recall: 0.17, F1: 0.26  \n",
    "  - Class 1 → Precision: 0.49, Recall: 0.90, F1: 0.63  \n",
    "  - Model favors Class 1 (positive detection).\n",
    "\n",
    "- **Threshold = 0.42**\n",
    "  - Accuracy: 0.52  \n",
    "  - Class 0 → Precision: 0.64, Recall: 0.24, F1: 0.35  \n",
    "  - Class 1 → Precision: 0.49, Recall: 0.84, F1: 0.62  \n",
    "  - Slightly more balanced, still biased toward Class 1.\n",
    "\n",
    "- **Threshold = 0.44**\n",
    "  - Accuracy: 0.54  \n",
    "  - Class 0 → Precision: 0.61, Recall: 0.36, F1: 0.45  \n",
    "  - Class 1 → Precision: 0.50, Recall: 0.74, F1: 0.60  \n",
    "  - Better trade-off, classes closer in recall.\n",
    "\n",
    "- **Threshold = 0.46**\n",
    "  - Accuracy: 0.55  \n",
    "  - Class 0 → Precision: 0.59, Recall: 0.52, F1: 0.55  \n",
    "  - Class 1 → Precision: 0.52, Recall: 0.59, F1: 0.55  \n",
    "  - Balanced detection across both classes.\n",
    "\n",
    "- **Threshold = 0.48**\n",
    "  - Accuracy: 0.56  \n",
    "  - Class 0 → Precision: 0.58, Recall: 0.68, F1: 0.62  \n",
    "  - Class 1 → Precision: 0.54, Recall: 0.43, F1: 0.48  \n",
    "  - Slightly favors Class 0.\n",
    "\n",
    "- **Threshold = 0.50 (Default)**  \n",
    "  - Accuracy: 0.56  \n",
    "  - Class 0 → Precision: 0.56, Recall: 0.80, F1: 0.66  \n",
    "  - Class 1 → Precision: 0.56, Recall: 0.29, F1: 0.38  \n",
    "  - Strong skew toward Class 0 detection.\n",
    "\n",
    "- **Threshold = 0.52**\n",
    "  - Accuracy: 0.56  \n",
    "  - Class 0 → Precision: 0.56, Recall: 0.89, F1: 0.68  \n",
    "  - Class 1 → Precision: 0.59, Recall: 0.19, F1: 0.29  \n",
    "  - Heavy bias toward Class 0.\n",
    "\n",
    "- **Threshold = 0.54**\n",
    "  - Accuracy: 0.56  \n",
    "  - Class 0 → Precision: 0.55, Recall: 0.93, F1: 0.69  \n",
    "  - Class 1 → Precision: 0.63, Recall: 0.13, F1: 0.22  \n",
    "  - Over-detects Class 0.\n",
    "\n",
    "- **Threshold = 0.56**\n",
    "  - Accuracy: 0.56  \n",
    "  - Class 0 → Precision: 0.55, Recall: 0.95, F1: 0.70  \n",
    "  - Class 1 → Precision: 0.66, Recall: 0.10, F1: 0.18  \n",
    "  - Severe imbalance toward Class 0.\n",
    "\n",
    "- **Threshold = 0.58**\n",
    "  - Accuracy: 0.55  \n",
    "  - Class 0 → Precision: 0.55, Recall: 0.97, F1: 0.70  \n",
    "  - Class 1 → Precision: 0.69, Recall: 0.08, F1: 0.15  \n",
    "  - Extreme skew toward Class 0.\n",
    "\n",
    "---\n",
    "\n",
    "#### Precision / Recall Matrix by Threshold\n",
    "\n",
    "| Threshold | Accuracy | Class 0 Precision | Class 0 Recall | Class 1 Precision | Class 1 Recall |\n",
    "|-----------|----------|-------------------|----------------|-------------------|----------------|\n",
    "| 0.40      | 0.51     | 0.66              | 0.17           | 0.49              | 0.90           |\n",
    "| 0.42      | 0.52     | 0.64              | 0.24           | 0.49              | 0.84           |\n",
    "| 0.44      | 0.54     | 0.61              | 0.36           | 0.50              | 0.74           |\n",
    "| 0.46      | 0.55     | 0.59              | 0.52           | 0.52              | 0.59           |\n",
    "| 0.48      | 0.56     | 0.58              | 0.68           | 0.54              | 0.43           |\n",
    "| 0.50      | 0.56     | 0.56              | 0.80           | 0.56              | 0.29           |\n",
    "| 0.52      | 0.56     | 0.56              | 0.89           | 0.59              | 0.19           |\n",
    "| 0.54      | 0.56     | 0.55              | 0.93           | 0.63              | 0.13           |\n",
    "| 0.56      | 0.56     | 0.55              | 0.95           | 0.66              | 0.10           |\n",
    "| 0.58      | 0.55     | 0.55              | 0.97           | 0.69              | 0.08           |\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaway**  \n",
    "- **Threshold 0.40–0.44** → High recall for Class 1 (positive detection), poor Class 0.  \n",
    "- **Threshold 0.46–0.48** → Best balance (both classes around 0.55 F1).  \n",
    "- **Threshold ≥ 0.50** → Accuracy remains ~0.56, but Class 1 recall drops sharply.  \n",
    "- **Optimal range: 0.46–0.48** for balanced precision/recall.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663fab2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
