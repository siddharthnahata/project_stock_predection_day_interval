{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e401004",
   "metadata": {},
   "source": [
    "## **2. This notebook is for model testing and finding best code and model for Classification model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91b791",
   "metadata": {},
   "source": [
    "**Importing necessary library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bea4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import ta\n",
    "import concurrent.futures # for faster data fectching\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# all the necessary library for the model building and it's evaluations\n",
    "\n",
    "## evaluation function and objects\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, roc_auc_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "## data preprocessing function and objects\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "## model building and algorithms\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709e671",
   "metadata": {},
   "source": [
    "### **2.1 --> fetching data and looking data creating new feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2302af",
   "metadata": {},
   "source": [
    "#### 2.11 fetching data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e583296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function can be used when updating the model and in production model updating\n",
    "def data_fetch_feature_generation(ticker: str):\n",
    "    try:\n",
    "        t = yf.Ticker(ticker)\n",
    "\n",
    "        # Fetch price history\n",
    "        df = t.history(interval=\"1d\", period=\"5y\")\n",
    "        if df.empty:\n",
    "            print(f\"[WARN] No data for {ticker}\")\n",
    "            return None, None, None\n",
    "\n",
    "        df.index = df.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Technical indicators\n",
    "        df[\"return_1d\"] = df[\"Close\"].pct_change(1)\n",
    "        df[\"return_7d\"] = df[\"Close\"].pct_change(7)\n",
    "        df[\"return_30d\"] = df[\"Close\"].pct_change(30)\n",
    "        df[\"return_180d\"] = df[\"Close\"].pct_change(180)\n",
    "        df[\"return_365d\"] = df[\"Close\"].pct_change(365)\n",
    "        df['rsi'] = ta.momentum.RSIIndicator(df['Close']).rsi()\n",
    "        df['macd'] = ta.trend.MACD(df['Close']).macd()\n",
    "        df[\"stoch\"] = ta.momentum.StochasticOscillator(df[\"High\"], df[\"Low\"], df[\"Close\"]).stoch()\n",
    "        df[\"roc\"] = ta.momentum.ROCIndicator(df[\"Close\"]).roc()\n",
    "        df[\"williams_r\"] = ta.momentum.WilliamsRIndicator(df[\"High\"], df[\"Low\"], df[\"Close\"]).williams_r()\n",
    "        df[\"realized_vol_5\"] = df[\"return_1d\"].rolling(5).std()\n",
    "        df[\"rolling_std_5\"]  = df[\"Close\"].rolling(5).std()\n",
    "        df[\"rolling_skew_5\"] = df[\"Close\"].rolling(5).skew()\n",
    "        df[\"rolling_kurt_5\"] = df[\"Close\"].rolling(5).kurt()\n",
    "        df['sma5'] = df['Close'].rolling(5).mean()\n",
    "        df['sma10'] = df['Close'].rolling(10).mean()\n",
    "        df['sma20'] = df['Close'].rolling(20).mean()\n",
    "        df['sma50'] = df['Close'].rolling(50).mean()\n",
    "        df['sma100'] = df['Close'].rolling(100).mean()\n",
    "        df['sma200'] = df['Close'].rolling(200).mean()\n",
    "        df[\"vwap\"] = (df[\"Volume\"] * (df[\"High\"]+df[\"Low\"]+df[\"Close\"])/3).cumsum() / df[\"Volume\"].cumsum()\n",
    "        df[\"volume_change\"] = df[\"Volume\"].pct_change()\n",
    "\n",
    "        # Safe sector info\n",
    "        sector = t.info.get('sector', 'Unknown')\n",
    "        df['sector'] = sector\n",
    "\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df['day_of_week'] = df.index.day_name()\n",
    "        \n",
    "        df['ticker'] = ticker\n",
    "\n",
    "        # Target (next-day return direction)\n",
    "        df['target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "\n",
    "        # Drop missing rows\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # Features & labels\n",
    "        X = df[['return_1d', 'return_7d', 'return_30d', 'return_180d', 'return_365d', 'stoch', 'roc', 'williams_r', 'realized_vol_5', 'rolling_std_5', 'rolling_skew_5', 'rolling_kurt_5', 'rsi','macd','sma5','Volume', 'sma10','sma20','sma50','sma100','sma200','sector', 'vwap', 'volume_change', 'day_of_week', 'ticker']]\n",
    "        y = df['target']\n",
    "\n",
    "        return df, X, y\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed for {ticker}: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f351e3",
   "metadata": {},
   "source": [
    "#### 2.12 Defining ticker for which data is to be fetched (list of 1000+ ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9948f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_nse():\n",
    "    URL = \"https://nsearchives.nseindia.com/content/equities/EQUITY_L.csv\"\n",
    "    \"This Function will only work for above link\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Accept\": \"text/csv\"\n",
    "    }\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    df = pd.read_csv(io.StringIO(response.text))\n",
    "    tickers = df['SYMBOL'].apply(lambda x: f\"{x}.NS\").tolist()\n",
    "    return tickers\n",
    "\n",
    "tickers_ns = get_ticker_nse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d5474",
   "metadata": {},
   "source": [
    "#### 2.13 simple for loop to fetch data for all the tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29da62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for 3PLAND.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TMB.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TITAGARH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TIRUPATIFL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TIPSFILMS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TIPSMUSIC.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TIIL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TIRUMALCHM.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TNTELE.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TORNTPOWER.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TNPETRO.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TITAN.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TOLINS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRANSWORLD.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRACXN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TREJHARA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TREL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRF.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TNPL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TOKYOPLAST.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TOUCHWOOD.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TORNTPHARM.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRANSRAILL.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TOTAL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TPHQ.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TRAVELFOOD.NS: Too Many Requests. Rate limited. Try after a while.[ERROR] Failed for TPLPLASTEH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "\n",
      "[ERROR] Failed for TRITURBINE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRENT.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TREEHOUSE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRIGYN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRIDENT.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TVSSCS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRIVENI.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TRU.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TVSSRICHAK.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TVSMOTOR.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TTML.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TTKHLTCARE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TTKPRESTIG.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UDS.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TVVISION.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for UCAL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TTL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UBL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TVSELECT.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UFO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for TVTODAY.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for UGROCAP.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UCOBANK.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UGARSUGAR.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for TVSHLTD.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UFLEX.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for UJJIVANSFB.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UMAEXPORTS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIECOM.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIDT.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for UMESLTD.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UMIYA-MRO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ULTRACEMCO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNICHEMLAB.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIINFO.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n",
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for UNIONBANK.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNITECH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNITEDPOLY.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIVASTU.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIMECH.NS: Too Many Requests. Rate limited. Try after a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 401: {\"finance\":{\"result\":null,\"error\":{\"code\":\"Unauthorized\",\"description\":\"Invalid Crumb\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for UNIVCABLES.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIVPHOTO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNITDSPR.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIPARTS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VAIBHAVGBL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for V2RETAIL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNIENTER.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for URBANCO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UYFINCORP.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNITEDTEA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VADILALIND.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UTTAMSUGAR.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VALIANTLAB.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for URAVIDEF.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for USK.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for USHAMART.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UTIAMC.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VARDMNPOLY.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VALIANTORG.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UNOMINDA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VARDHACRLC.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for URJA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VAISHALI.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VAKRANGEE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UPL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for UTKARSHBNK.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VASWANI.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VBL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VASCONEQ.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VARROC.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VEEDOL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VCL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VEDL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VENTIVE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VENUSPIPES.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VENKEYS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VENUSREM.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VETO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VERANDA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VERTOZ.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VHLTD.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIKASECO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VESUVIUS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIJAYA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIJIFIN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VGUARD.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VHL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIDHIING.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIKRAN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VINCOFE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIKRAMSOLR.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIKASLIFE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VINEETLAB.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VINDHYATEL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIPCLOTHNG.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VINYLINDIA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VINNY.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIPIND.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIMTALABS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VINATIORGA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIPULLTD.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VISAKAIND.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIRINCHI.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VISHNU.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VMART.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VISHWARAJ.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VMM.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VLSFINANCE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VIVIDHA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VLEGOV.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VMSTMT.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VOLTAS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VRLLOG.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VPRPL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VSSL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VOLTAMP.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VRAJ.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VTL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VSTIND.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WAAREEENER.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VSTL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for VSTTILLERS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WAAREERTL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WCIL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WALCHANNAG.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WABAG.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WANBURY.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WEL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WEBELSOLAR.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WEALTH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WEIZMANIND.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WELCORP.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WENDT.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WELINV.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WELENT.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WELSPUNLIV.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WESTLIFE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WEWIN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WHEELS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WHIRLPOOL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WINDMACHIN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WILLAMAGOR.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WINDLAS.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WINSOME.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WIPRO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WONDERLA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WIPL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WOCKPHARMA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for XCHANGING.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for XELPMOC.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for XPROINDIA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for XTGLOBAL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WSTCSTPAPR.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WORTH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for WSI.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for YUKEN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for YESBANK.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for YASHO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZAGGLE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for YATHARTH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for YATRA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZEEMEDIA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZEEL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZEELEARN.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZENITHEXPO.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZIMLAB.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZFCVINDIA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZODIACLOTH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZENTEC.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZENSARTECH.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZYDUSLIFE.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZENITHSTL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZODIAC.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZYDUSWELL.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZOTA.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZUARIIND.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "[ERROR] Failed for ZUARI.NS: Too Many Requests. Rate limited. Try after a while.\n",
      "1/2160 done\n",
      "2/2160 done\n",
      "3/2160 done\n",
      "4/2160 done\n",
      "5/2160 done\n",
      "6/2160 skipped\n",
      "7/2160 done\n",
      "8/2160 done\n",
      "9/2160 done\n",
      "10/2160 done\n",
      "11/2160 done\n",
      "12/2160 done\n",
      "13/2160 done\n",
      "14/2160 done\n",
      "15/2160 done\n",
      "16/2160 done\n",
      "17/2160 done\n",
      "18/2160 done\n",
      "19/2160 done\n",
      "20/2160 done\n",
      "21/2160 done\n",
      "22/2160 done\n",
      "23/2160 done\n",
      "24/2160 done\n",
      "25/2160 done\n",
      "26/2160 done\n",
      "27/2160 done\n",
      "28/2160 done\n",
      "29/2160 done\n",
      "30/2160 done\n",
      "31/2160 done\n",
      "32/2160 done\n",
      "33/2160 done\n",
      "34/2160 done\n",
      "35/2160 done\n",
      "36/2160 done\n",
      "37/2160 done\n",
      "38/2160 done\n",
      "39/2160 done\n",
      "40/2160 done\n",
      "41/2160 done\n",
      "42/2160 done\n",
      "43/2160 done\n",
      "44/2160 done\n",
      "45/2160 done\n",
      "46/2160 done\n",
      "47/2160 done\n",
      "48/2160 done\n",
      "49/2160 done\n",
      "50/2160 done\n",
      "51/2160 done\n",
      "52/2160 done\n",
      "53/2160 done\n",
      "54/2160 done\n",
      "55/2160 done\n",
      "56/2160 done\n",
      "57/2160 done\n",
      "58/2160 done\n",
      "59/2160 done\n",
      "60/2160 done\n",
      "61/2160 done\n",
      "62/2160 done\n",
      "63/2160 done\n",
      "64/2160 done\n",
      "65/2160 done\n",
      "66/2160 done\n",
      "67/2160 done\n",
      "68/2160 done\n",
      "69/2160 done\n",
      "70/2160 done\n",
      "71/2160 done\n",
      "72/2160 done\n",
      "73/2160 done\n",
      "74/2160 done\n",
      "75/2160 done\n",
      "76/2160 done\n",
      "77/2160 done\n",
      "78/2160 done\n",
      "79/2160 done\n",
      "80/2160 done\n",
      "81/2160 done\n",
      "82/2160 done\n",
      "83/2160 done\n",
      "84/2160 done\n",
      "85/2160 done\n",
      "86/2160 done\n",
      "87/2160 done\n",
      "88/2160 done\n",
      "89/2160 done\n",
      "90/2160 done\n",
      "91/2160 done\n",
      "92/2160 done\n",
      "93/2160 done\n",
      "94/2160 done\n",
      "95/2160 done\n",
      "96/2160 done\n",
      "97/2160 done\n",
      "98/2160 done\n",
      "99/2160 done\n",
      "100/2160 done\n",
      "101/2160 done\n",
      "102/2160 done\n",
      "103/2160 done\n",
      "104/2160 done\n",
      "105/2160 done\n",
      "106/2160 done\n",
      "107/2160 done\n",
      "108/2160 done\n",
      "109/2160 done\n",
      "110/2160 done\n",
      "111/2160 done\n",
      "112/2160 done\n",
      "113/2160 done\n",
      "114/2160 done\n",
      "115/2160 done\n",
      "116/2160 done\n",
      "117/2160 done\n",
      "118/2160 done\n",
      "119/2160 done\n",
      "120/2160 done\n",
      "121/2160 done\n",
      "122/2160 done\n",
      "123/2160 done\n",
      "124/2160 done\n",
      "125/2160 done\n",
      "126/2160 done\n",
      "127/2160 done\n",
      "128/2160 done\n",
      "129/2160 done\n",
      "130/2160 done\n",
      "131/2160 done\n",
      "132/2160 done\n",
      "133/2160 done\n",
      "134/2160 done\n",
      "135/2160 done\n",
      "136/2160 done\n",
      "137/2160 done\n",
      "138/2160 done\n",
      "139/2160 done\n",
      "140/2160 done\n",
      "141/2160 done\n",
      "142/2160 done\n",
      "143/2160 done\n",
      "144/2160 done\n",
      "145/2160 done\n",
      "146/2160 done\n",
      "147/2160 done\n",
      "148/2160 done\n",
      "149/2160 done\n",
      "150/2160 done\n",
      "151/2160 done\n",
      "152/2160 done\n",
      "153/2160 done\n",
      "154/2160 done\n",
      "155/2160 done\n",
      "156/2160 done\n",
      "157/2160 done\n",
      "158/2160 done\n",
      "159/2160 done\n",
      "160/2160 done\n",
      "161/2160 done\n",
      "162/2160 done\n",
      "163/2160 done\n",
      "164/2160 done\n",
      "165/2160 done\n",
      "166/2160 done\n",
      "167/2160 done\n",
      "168/2160 done\n",
      "169/2160 done\n",
      "170/2160 done\n",
      "171/2160 done\n",
      "172/2160 done\n",
      "173/2160 done\n",
      "174/2160 done\n",
      "175/2160 done\n",
      "176/2160 done\n",
      "177/2160 done\n",
      "178/2160 done\n",
      "179/2160 done\n",
      "180/2160 done\n",
      "181/2160 done\n",
      "182/2160 done\n",
      "183/2160 done\n",
      "184/2160 done\n",
      "185/2160 done\n",
      "186/2160 done\n",
      "187/2160 done\n",
      "188/2160 done\n",
      "189/2160 done\n",
      "190/2160 done\n",
      "191/2160 done\n",
      "192/2160 done\n",
      "193/2160 done\n",
      "194/2160 done\n",
      "195/2160 done\n",
      "196/2160 done\n",
      "197/2160 done\n",
      "198/2160 done\n",
      "199/2160 done\n",
      "200/2160 done\n",
      "201/2160 done\n",
      "202/2160 done\n",
      "203/2160 done\n",
      "204/2160 done\n",
      "205/2160 done\n",
      "206/2160 done\n",
      "207/2160 done\n",
      "208/2160 done\n",
      "209/2160 done\n",
      "210/2160 done\n",
      "211/2160 done\n",
      "212/2160 done\n",
      "213/2160 done\n",
      "214/2160 done\n",
      "215/2160 done\n",
      "216/2160 done\n",
      "217/2160 done\n",
      "218/2160 done\n",
      "219/2160 done\n",
      "220/2160 done\n",
      "221/2160 done\n",
      "222/2160 done\n",
      "223/2160 done\n",
      "224/2160 done\n",
      "225/2160 done\n",
      "226/2160 done\n",
      "227/2160 done\n",
      "228/2160 done\n",
      "229/2160 done\n",
      "230/2160 done\n",
      "231/2160 done\n",
      "232/2160 done\n",
      "233/2160 done\n",
      "234/2160 done\n",
      "235/2160 done\n",
      "236/2160 done\n",
      "237/2160 done\n",
      "238/2160 done\n",
      "239/2160 done\n",
      "240/2160 done\n",
      "241/2160 done\n",
      "242/2160 done\n",
      "243/2160 done\n",
      "244/2160 done\n",
      "245/2160 done\n",
      "246/2160 done\n",
      "247/2160 done\n",
      "248/2160 done\n",
      "249/2160 done\n",
      "250/2160 done\n",
      "251/2160 done\n",
      "252/2160 done\n",
      "253/2160 done\n",
      "254/2160 done\n",
      "255/2160 done\n",
      "256/2160 done\n",
      "257/2160 done\n",
      "258/2160 done\n",
      "259/2160 done\n",
      "260/2160 done\n",
      "261/2160 done\n",
      "262/2160 done\n",
      "263/2160 done\n",
      "264/2160 done\n",
      "265/2160 done\n",
      "266/2160 done\n",
      "267/2160 done\n",
      "268/2160 done\n",
      "269/2160 done\n",
      "270/2160 done\n",
      "271/2160 done\n",
      "272/2160 done\n",
      "273/2160 done\n",
      "274/2160 done\n",
      "275/2160 done\n",
      "276/2160 done\n",
      "277/2160 done\n",
      "278/2160 done\n",
      "279/2160 done\n",
      "280/2160 done\n",
      "281/2160 done\n",
      "282/2160 done\n",
      "283/2160 done\n",
      "284/2160 done\n",
      "285/2160 done\n",
      "286/2160 done\n",
      "287/2160 done\n",
      "288/2160 done\n",
      "289/2160 done\n",
      "290/2160 done\n",
      "291/2160 done\n",
      "292/2160 done\n",
      "293/2160 done\n",
      "294/2160 done\n",
      "295/2160 done\n",
      "296/2160 done\n",
      "297/2160 done\n",
      "298/2160 done\n",
      "299/2160 done\n",
      "300/2160 done\n",
      "301/2160 done\n",
      "302/2160 done\n",
      "303/2160 done\n",
      "304/2160 done\n",
      "305/2160 done\n",
      "306/2160 done\n",
      "307/2160 done\n",
      "308/2160 done\n",
      "309/2160 done\n",
      "310/2160 done\n",
      "311/2160 done\n",
      "312/2160 done\n",
      "313/2160 done\n",
      "314/2160 done\n",
      "315/2160 done\n",
      "316/2160 done\n",
      "317/2160 done\n",
      "318/2160 done\n",
      "319/2160 done\n",
      "320/2160 done\n",
      "321/2160 done\n",
      "322/2160 done\n",
      "323/2160 done\n",
      "324/2160 done\n",
      "325/2160 done\n",
      "326/2160 done\n",
      "327/2160 done\n",
      "328/2160 done\n",
      "329/2160 done\n",
      "330/2160 done\n",
      "331/2160 done\n",
      "332/2160 done\n",
      "333/2160 done\n",
      "334/2160 done\n",
      "335/2160 done\n",
      "336/2160 done\n",
      "337/2160 done\n",
      "338/2160 done\n",
      "339/2160 done\n",
      "340/2160 done\n",
      "341/2160 done\n",
      "342/2160 done\n",
      "343/2160 done\n",
      "344/2160 done\n",
      "345/2160 done\n",
      "346/2160 done\n",
      "347/2160 done\n",
      "348/2160 done\n",
      "349/2160 done\n",
      "350/2160 done\n",
      "351/2160 done\n",
      "352/2160 done\n",
      "353/2160 done\n",
      "354/2160 done\n",
      "355/2160 done\n",
      "356/2160 done\n",
      "357/2160 done\n",
      "358/2160 done\n",
      "359/2160 done\n",
      "360/2160 done\n",
      "361/2160 done\n",
      "362/2160 done\n",
      "363/2160 done\n",
      "364/2160 done\n",
      "365/2160 done\n",
      "366/2160 done\n",
      "367/2160 done\n",
      "368/2160 done\n",
      "369/2160 done\n",
      "370/2160 done\n",
      "371/2160 done\n",
      "372/2160 done\n",
      "373/2160 done\n",
      "374/2160 done\n",
      "375/2160 done\n",
      "376/2160 done\n",
      "377/2160 done\n",
      "378/2160 done\n",
      "379/2160 done\n",
      "380/2160 done\n",
      "381/2160 done\n",
      "382/2160 done\n",
      "383/2160 done\n",
      "384/2160 done\n",
      "385/2160 done\n",
      "386/2160 done\n",
      "387/2160 done\n",
      "388/2160 done\n",
      "389/2160 done\n",
      "390/2160 done\n",
      "391/2160 done\n",
      "392/2160 done\n",
      "393/2160 done\n",
      "394/2160 done\n",
      "395/2160 done\n",
      "396/2160 done\n",
      "397/2160 done\n",
      "398/2160 done\n",
      "399/2160 done\n",
      "400/2160 done\n",
      "401/2160 done\n",
      "402/2160 done\n",
      "403/2160 done\n",
      "404/2160 done\n",
      "405/2160 done\n",
      "406/2160 done\n",
      "407/2160 done\n",
      "408/2160 done\n",
      "409/2160 done\n",
      "410/2160 done\n",
      "411/2160 done\n",
      "412/2160 done\n",
      "413/2160 done\n",
      "414/2160 done\n",
      "415/2160 done\n",
      "416/2160 done\n",
      "417/2160 done\n",
      "418/2160 done\n",
      "419/2160 done\n",
      "420/2160 done\n",
      "421/2160 done\n",
      "422/2160 done\n",
      "423/2160 done\n",
      "424/2160 done\n",
      "425/2160 done\n",
      "426/2160 done\n",
      "427/2160 done\n",
      "428/2160 done\n",
      "429/2160 done\n",
      "430/2160 done\n",
      "431/2160 done\n",
      "432/2160 done\n",
      "433/2160 done\n",
      "434/2160 done\n",
      "435/2160 done\n",
      "436/2160 done\n",
      "437/2160 done\n",
      "438/2160 done\n",
      "439/2160 done\n",
      "440/2160 done\n",
      "441/2160 done\n",
      "442/2160 done\n",
      "443/2160 done\n",
      "444/2160 done\n",
      "445/2160 done\n",
      "446/2160 done\n",
      "447/2160 done\n",
      "448/2160 done\n",
      "449/2160 done\n",
      "450/2160 done\n",
      "451/2160 done\n",
      "452/2160 done\n",
      "453/2160 done\n",
      "454/2160 done\n",
      "455/2160 done\n",
      "456/2160 done\n",
      "457/2160 done\n",
      "458/2160 done\n",
      "459/2160 done\n",
      "460/2160 done\n",
      "461/2160 done\n",
      "462/2160 done\n",
      "463/2160 done\n",
      "464/2160 done\n",
      "465/2160 done\n",
      "466/2160 done\n",
      "467/2160 done\n",
      "468/2160 done\n",
      "469/2160 done\n",
      "470/2160 done\n",
      "471/2160 done\n",
      "472/2160 done\n",
      "473/2160 done\n",
      "474/2160 done\n",
      "475/2160 done\n",
      "476/2160 done\n",
      "477/2160 done\n",
      "478/2160 done\n",
      "479/2160 done\n",
      "480/2160 done\n",
      "481/2160 done\n",
      "482/2160 done\n",
      "483/2160 done\n",
      "484/2160 done\n",
      "485/2160 done\n",
      "486/2160 done\n",
      "487/2160 done\n",
      "488/2160 done\n",
      "489/2160 done\n",
      "490/2160 done\n",
      "491/2160 done\n",
      "492/2160 done\n",
      "493/2160 done\n",
      "494/2160 done\n",
      "495/2160 done\n",
      "496/2160 done\n",
      "497/2160 done\n",
      "498/2160 done\n",
      "499/2160 done\n",
      "500/2160 done\n",
      "501/2160 done\n",
      "502/2160 done\n",
      "503/2160 done\n",
      "504/2160 done\n",
      "505/2160 done\n",
      "506/2160 done\n",
      "507/2160 done\n",
      "508/2160 done\n",
      "509/2160 done\n",
      "510/2160 done\n",
      "511/2160 done\n",
      "512/2160 done\n",
      "513/2160 done\n",
      "514/2160 done\n",
      "515/2160 done\n",
      "516/2160 done\n",
      "517/2160 done\n",
      "518/2160 done\n",
      "519/2160 done\n",
      "520/2160 done\n",
      "521/2160 done\n",
      "522/2160 done\n",
      "523/2160 done\n",
      "524/2160 done\n",
      "525/2160 done\n",
      "526/2160 done\n",
      "527/2160 done\n",
      "528/2160 done\n",
      "529/2160 done\n",
      "530/2160 done\n",
      "531/2160 done\n",
      "532/2160 done\n",
      "533/2160 done\n",
      "534/2160 done\n",
      "535/2160 done\n",
      "536/2160 done\n",
      "537/2160 done\n",
      "538/2160 done\n",
      "539/2160 done\n",
      "540/2160 done\n",
      "541/2160 done\n",
      "542/2160 done\n",
      "543/2160 done\n",
      "544/2160 done\n",
      "545/2160 done\n",
      "546/2160 done\n",
      "547/2160 done\n",
      "548/2160 done\n",
      "549/2160 done\n",
      "550/2160 done\n",
      "551/2160 done\n",
      "552/2160 done\n",
      "553/2160 done\n",
      "554/2160 done\n",
      "555/2160 done\n",
      "556/2160 done\n",
      "557/2160 done\n",
      "558/2160 done\n",
      "559/2160 done\n",
      "560/2160 done\n",
      "561/2160 done\n",
      "562/2160 done\n",
      "563/2160 done\n",
      "564/2160 done\n",
      "565/2160 done\n",
      "566/2160 done\n",
      "567/2160 done\n",
      "568/2160 done\n",
      "569/2160 done\n",
      "570/2160 done\n",
      "571/2160 done\n",
      "572/2160 done\n",
      "573/2160 done\n",
      "574/2160 done\n",
      "575/2160 done\n",
      "576/2160 done\n",
      "577/2160 done\n",
      "578/2160 done\n",
      "579/2160 done\n",
      "580/2160 done\n",
      "581/2160 done\n",
      "582/2160 done\n",
      "583/2160 done\n",
      "584/2160 done\n",
      "585/2160 done\n",
      "586/2160 done\n",
      "587/2160 done\n",
      "588/2160 done\n",
      "589/2160 done\n",
      "590/2160 done\n",
      "591/2160 done\n",
      "592/2160 done\n",
      "593/2160 done\n",
      "594/2160 done\n",
      "595/2160 done\n",
      "596/2160 done\n",
      "597/2160 done\n",
      "598/2160 done\n",
      "599/2160 done\n",
      "600/2160 done\n",
      "601/2160 done\n",
      "602/2160 done\n",
      "603/2160 done\n",
      "604/2160 done\n",
      "605/2160 done\n",
      "606/2160 done\n",
      "607/2160 done\n",
      "608/2160 done\n",
      "609/2160 done\n",
      "610/2160 done\n",
      "611/2160 done\n",
      "612/2160 done\n",
      "613/2160 done\n",
      "614/2160 done\n",
      "615/2160 done\n",
      "616/2160 done\n",
      "617/2160 done\n",
      "618/2160 done\n",
      "619/2160 done\n",
      "620/2160 done\n",
      "621/2160 done\n",
      "622/2160 done\n",
      "623/2160 done\n",
      "624/2160 done\n",
      "625/2160 done\n",
      "626/2160 done\n",
      "627/2160 done\n",
      "628/2160 done\n",
      "629/2160 done\n",
      "630/2160 done\n",
      "631/2160 done\n",
      "632/2160 done\n",
      "633/2160 done\n",
      "634/2160 done\n",
      "635/2160 done\n",
      "636/2160 done\n",
      "637/2160 done\n",
      "638/2160 done\n",
      "639/2160 done\n",
      "640/2160 done\n",
      "641/2160 done\n",
      "642/2160 done\n",
      "643/2160 done\n",
      "644/2160 done\n",
      "645/2160 done\n",
      "646/2160 done\n",
      "647/2160 done\n",
      "648/2160 done\n",
      "649/2160 done\n",
      "650/2160 done\n",
      "651/2160 done\n",
      "652/2160 done\n",
      "653/2160 done\n",
      "654/2160 done\n",
      "655/2160 done\n",
      "656/2160 done\n",
      "657/2160 done\n",
      "658/2160 done\n",
      "659/2160 done\n",
      "660/2160 done\n",
      "661/2160 done\n",
      "662/2160 done\n",
      "663/2160 done\n",
      "664/2160 done\n",
      "665/2160 done\n",
      "666/2160 done\n",
      "667/2160 done\n",
      "668/2160 done\n",
      "669/2160 done\n",
      "670/2160 done\n",
      "671/2160 done\n",
      "672/2160 done\n",
      "673/2160 done\n",
      "674/2160 done\n",
      "675/2160 done\n",
      "676/2160 done\n",
      "677/2160 done\n",
      "678/2160 done\n",
      "679/2160 done\n",
      "680/2160 done\n",
      "681/2160 done\n",
      "682/2160 done\n",
      "683/2160 done\n",
      "684/2160 done\n",
      "685/2160 done\n",
      "686/2160 done\n",
      "687/2160 done\n",
      "688/2160 done\n",
      "689/2160 done\n",
      "690/2160 done\n",
      "691/2160 done\n",
      "692/2160 done\n",
      "693/2160 done\n",
      "694/2160 done\n",
      "695/2160 done\n",
      "696/2160 done\n",
      "697/2160 done\n",
      "698/2160 done\n",
      "699/2160 done\n",
      "700/2160 done\n",
      "701/2160 done\n",
      "702/2160 done\n",
      "703/2160 done\n",
      "704/2160 done\n",
      "705/2160 done\n",
      "706/2160 done\n",
      "707/2160 done\n",
      "708/2160 done\n",
      "709/2160 done\n",
      "710/2160 done\n",
      "711/2160 done\n",
      "712/2160 done\n",
      "713/2160 done\n",
      "714/2160 done\n",
      "715/2160 done\n",
      "716/2160 done\n",
      "717/2160 done\n",
      "718/2160 done\n",
      "719/2160 done\n",
      "720/2160 done\n",
      "721/2160 done\n",
      "722/2160 done\n",
      "723/2160 done\n",
      "724/2160 done\n",
      "725/2160 done\n",
      "726/2160 done\n",
      "727/2160 done\n",
      "728/2160 done\n",
      "729/2160 done\n",
      "730/2160 done\n",
      "731/2160 done\n",
      "732/2160 done\n",
      "733/2160 done\n",
      "734/2160 done\n",
      "735/2160 done\n",
      "736/2160 done\n",
      "737/2160 done\n",
      "738/2160 done\n",
      "739/2160 done\n",
      "740/2160 done\n",
      "741/2160 done\n",
      "742/2160 done\n",
      "743/2160 done\n",
      "744/2160 done\n",
      "745/2160 done\n",
      "746/2160 done\n",
      "747/2160 done\n",
      "748/2160 done\n",
      "749/2160 done\n",
      "750/2160 done\n",
      "751/2160 done\n",
      "752/2160 done\n",
      "753/2160 done\n",
      "754/2160 done\n",
      "755/2160 done\n",
      "756/2160 done\n",
      "757/2160 done\n",
      "758/2160 done\n",
      "759/2160 done\n",
      "760/2160 done\n",
      "761/2160 done\n",
      "762/2160 done\n",
      "763/2160 done\n",
      "764/2160 done\n",
      "765/2160 done\n",
      "766/2160 done\n",
      "767/2160 done\n",
      "768/2160 done\n",
      "769/2160 done\n",
      "770/2160 done\n",
      "771/2160 done\n",
      "772/2160 done\n",
      "773/2160 done\n",
      "774/2160 done\n",
      "775/2160 done\n",
      "776/2160 done\n",
      "777/2160 done\n",
      "778/2160 done\n",
      "779/2160 done\n",
      "780/2160 done\n",
      "781/2160 done\n",
      "782/2160 done\n",
      "783/2160 done\n",
      "784/2160 done\n",
      "785/2160 done\n",
      "786/2160 done\n",
      "787/2160 done\n",
      "788/2160 done\n",
      "789/2160 done\n",
      "790/2160 done\n",
      "791/2160 done\n",
      "792/2160 done\n",
      "793/2160 done\n",
      "794/2160 done\n",
      "795/2160 done\n",
      "796/2160 done\n",
      "797/2160 done\n",
      "798/2160 done\n",
      "799/2160 done\n",
      "800/2160 done\n",
      "801/2160 done\n",
      "802/2160 done\n",
      "803/2160 done\n",
      "804/2160 done\n",
      "805/2160 done\n",
      "806/2160 done\n",
      "807/2160 done\n",
      "808/2160 done\n",
      "809/2160 done\n",
      "810/2160 done\n",
      "811/2160 done\n",
      "812/2160 done\n",
      "813/2160 done\n",
      "814/2160 done\n",
      "815/2160 done\n",
      "816/2160 done\n",
      "817/2160 done\n",
      "818/2160 done\n",
      "819/2160 done\n",
      "820/2160 done\n",
      "821/2160 done\n",
      "822/2160 done\n",
      "823/2160 done\n",
      "824/2160 done\n",
      "825/2160 done\n",
      "826/2160 done\n",
      "827/2160 done\n",
      "828/2160 done\n",
      "829/2160 done\n",
      "830/2160 done\n",
      "831/2160 done\n",
      "832/2160 done\n",
      "833/2160 done\n",
      "834/2160 done\n",
      "835/2160 done\n",
      "836/2160 done\n",
      "837/2160 done\n",
      "838/2160 done\n",
      "839/2160 done\n",
      "840/2160 done\n",
      "841/2160 done\n",
      "842/2160 done\n",
      "843/2160 done\n",
      "844/2160 done\n",
      "845/2160 done\n",
      "846/2160 done\n",
      "847/2160 done\n",
      "848/2160 done\n",
      "849/2160 done\n",
      "850/2160 done\n",
      "851/2160 done\n",
      "852/2160 done\n",
      "853/2160 done\n",
      "854/2160 done\n",
      "855/2160 done\n",
      "856/2160 done\n",
      "857/2160 done\n",
      "858/2160 done\n",
      "859/2160 done\n",
      "860/2160 done\n",
      "861/2160 done\n",
      "862/2160 done\n",
      "863/2160 done\n",
      "864/2160 done\n",
      "865/2160 done\n",
      "866/2160 done\n",
      "867/2160 done\n",
      "868/2160 done\n",
      "869/2160 done\n",
      "870/2160 done\n",
      "871/2160 done\n",
      "872/2160 done\n",
      "873/2160 done\n",
      "874/2160 done\n",
      "875/2160 done\n",
      "876/2160 done\n",
      "877/2160 done\n",
      "878/2160 done\n",
      "879/2160 done\n",
      "880/2160 done\n",
      "881/2160 done\n",
      "882/2160 done\n",
      "883/2160 done\n",
      "884/2160 done\n",
      "885/2160 done\n",
      "886/2160 done\n",
      "887/2160 done\n",
      "888/2160 done\n",
      "889/2160 done\n",
      "890/2160 done\n",
      "891/2160 done\n",
      "892/2160 done\n",
      "893/2160 done\n",
      "894/2160 done\n",
      "895/2160 done\n",
      "896/2160 done\n",
      "897/2160 done\n",
      "898/2160 done\n",
      "899/2160 done\n",
      "900/2160 done\n",
      "901/2160 done\n",
      "902/2160 done\n",
      "903/2160 done\n",
      "904/2160 done\n",
      "905/2160 done\n",
      "906/2160 done\n",
      "907/2160 done\n",
      "908/2160 done\n",
      "909/2160 done\n",
      "910/2160 done\n",
      "911/2160 done\n",
      "912/2160 done\n",
      "913/2160 done\n",
      "914/2160 done\n",
      "915/2160 done\n",
      "916/2160 done\n",
      "917/2160 done\n",
      "918/2160 done\n",
      "919/2160 done\n",
      "920/2160 done\n",
      "921/2160 done\n",
      "922/2160 done\n",
      "923/2160 done\n",
      "924/2160 done\n",
      "925/2160 done\n",
      "926/2160 done\n",
      "927/2160 done\n",
      "928/2160 done\n",
      "929/2160 done\n",
      "930/2160 done\n",
      "931/2160 done\n",
      "932/2160 done\n",
      "933/2160 done\n",
      "934/2160 done\n",
      "935/2160 done\n",
      "936/2160 done\n",
      "937/2160 done\n",
      "938/2160 done\n",
      "939/2160 done\n",
      "940/2160 done\n",
      "941/2160 done\n",
      "942/2160 done\n",
      "943/2160 done\n",
      "944/2160 done\n",
      "945/2160 done\n",
      "946/2160 done\n",
      "947/2160 done\n",
      "948/2160 done\n",
      "949/2160 done\n",
      "950/2160 done\n",
      "951/2160 done\n",
      "952/2160 done\n",
      "953/2160 done\n",
      "954/2160 done\n",
      "955/2160 done\n",
      "956/2160 done\n",
      "957/2160 done\n",
      "958/2160 done\n",
      "959/2160 done\n",
      "960/2160 done\n",
      "961/2160 done\n",
      "962/2160 done\n",
      "963/2160 done\n",
      "964/2160 done\n",
      "965/2160 done\n",
      "966/2160 done\n",
      "967/2160 done\n",
      "968/2160 done\n",
      "969/2160 done\n",
      "970/2160 done\n",
      "971/2160 done\n",
      "972/2160 done\n",
      "973/2160 done\n",
      "974/2160 done\n",
      "975/2160 done\n",
      "976/2160 done\n",
      "977/2160 done\n",
      "978/2160 done\n",
      "979/2160 done\n",
      "980/2160 done\n",
      "981/2160 done\n",
      "982/2160 done\n",
      "983/2160 done\n",
      "984/2160 done\n",
      "985/2160 done\n",
      "986/2160 done\n",
      "987/2160 done\n",
      "988/2160 done\n",
      "989/2160 done\n",
      "990/2160 done\n",
      "991/2160 done\n",
      "992/2160 done\n",
      "993/2160 done\n",
      "994/2160 done\n",
      "995/2160 done\n",
      "996/2160 done\n",
      "997/2160 done\n",
      "998/2160 done\n",
      "999/2160 done\n",
      "1000/2160 done\n",
      "1001/2160 done\n",
      "1002/2160 done\n",
      "1003/2160 done\n",
      "1004/2160 done\n",
      "1005/2160 done\n",
      "1006/2160 done\n",
      "1007/2160 done\n",
      "1008/2160 done\n",
      "1009/2160 done\n",
      "1010/2160 done\n",
      "1011/2160 done\n",
      "1012/2160 done\n",
      "1013/2160 done\n",
      "1014/2160 done\n",
      "1015/2160 done\n",
      "1016/2160 done\n",
      "1017/2160 done\n",
      "1018/2160 done\n",
      "1019/2160 done\n",
      "1020/2160 done\n",
      "1021/2160 done\n",
      "1022/2160 done\n",
      "1023/2160 done\n",
      "1024/2160 done\n",
      "1025/2160 done\n",
      "1026/2160 done\n",
      "1027/2160 done\n",
      "1028/2160 done\n",
      "1029/2160 done\n",
      "1030/2160 done\n",
      "1031/2160 done\n",
      "1032/2160 done\n",
      "1033/2160 done\n",
      "1034/2160 done\n",
      "1035/2160 done\n",
      "1036/2160 done\n",
      "1037/2160 done\n",
      "1038/2160 done\n",
      "1039/2160 done\n",
      "1040/2160 done\n",
      "1041/2160 done\n",
      "1042/2160 done\n",
      "1043/2160 done\n",
      "1044/2160 done\n",
      "1045/2160 done\n",
      "1046/2160 done\n",
      "1047/2160 done\n",
      "1048/2160 done\n",
      "1049/2160 done\n",
      "1050/2160 done\n",
      "1051/2160 done\n",
      "1052/2160 done\n",
      "1053/2160 done\n",
      "1054/2160 done\n",
      "1055/2160 done\n",
      "1056/2160 done\n",
      "1057/2160 done\n",
      "1058/2160 done\n",
      "1059/2160 done\n",
      "1060/2160 done\n",
      "1061/2160 done\n",
      "1062/2160 done\n",
      "1063/2160 done\n",
      "1064/2160 done\n",
      "1065/2160 done\n",
      "1066/2160 done\n",
      "1067/2160 done\n",
      "1068/2160 done\n",
      "1069/2160 done\n",
      "1070/2160 done\n",
      "1071/2160 done\n",
      "1072/2160 done\n",
      "1073/2160 done\n",
      "1074/2160 done\n",
      "1075/2160 done\n",
      "1076/2160 done\n",
      "1077/2160 done\n",
      "1078/2160 done\n",
      "1079/2160 done\n",
      "1080/2160 done\n",
      "1081/2160 done\n",
      "1082/2160 done\n",
      "1083/2160 done\n",
      "1084/2160 done\n",
      "1085/2160 done\n",
      "1086/2160 done\n",
      "1087/2160 done\n",
      "1088/2160 done\n",
      "1089/2160 done\n",
      "1090/2160 done\n",
      "1091/2160 done\n",
      "1092/2160 done\n",
      "1093/2160 done\n",
      "1094/2160 done\n",
      "1095/2160 done\n",
      "1096/2160 done\n",
      "1097/2160 done\n",
      "1098/2160 done\n",
      "1099/2160 done\n",
      "1100/2160 done\n",
      "1101/2160 done\n",
      "1102/2160 done\n",
      "1103/2160 done\n",
      "1104/2160 done\n",
      "1105/2160 done\n",
      "1106/2160 done\n",
      "1107/2160 done\n",
      "1108/2160 done\n",
      "1109/2160 done\n",
      "1110/2160 done\n",
      "1111/2160 done\n",
      "1112/2160 done\n",
      "1113/2160 done\n",
      "1114/2160 done\n",
      "1115/2160 done\n",
      "1116/2160 done\n",
      "1117/2160 done\n",
      "1118/2160 done\n",
      "1119/2160 done\n",
      "1120/2160 done\n",
      "1121/2160 done\n",
      "1122/2160 done\n",
      "1123/2160 done\n",
      "1124/2160 done\n",
      "1125/2160 done\n",
      "1126/2160 done\n",
      "1127/2160 done\n",
      "1128/2160 done\n",
      "1129/2160 done\n",
      "1130/2160 done\n",
      "1131/2160 done\n",
      "1132/2160 done\n",
      "1133/2160 done\n",
      "1134/2160 done\n",
      "1135/2160 done\n",
      "1136/2160 done\n",
      "1137/2160 done\n",
      "1138/2160 done\n",
      "1139/2160 done\n",
      "1140/2160 done\n",
      "1141/2160 done\n",
      "1142/2160 done\n",
      "1143/2160 done\n",
      "1144/2160 done\n",
      "1145/2160 done\n",
      "1146/2160 done\n",
      "1147/2160 done\n",
      "1148/2160 done\n",
      "1149/2160 done\n",
      "1150/2160 done\n",
      "1151/2160 done\n",
      "1152/2160 done\n",
      "1153/2160 done\n",
      "1154/2160 done\n",
      "1155/2160 done\n",
      "1156/2160 done\n",
      "1157/2160 done\n",
      "1158/2160 done\n",
      "1159/2160 done\n",
      "1160/2160 done\n",
      "1161/2160 done\n",
      "1162/2160 done\n",
      "1163/2160 done\n",
      "1164/2160 done\n",
      "1165/2160 done\n",
      "1166/2160 done\n",
      "1167/2160 done\n",
      "1168/2160 done\n",
      "1169/2160 done\n",
      "1170/2160 done\n",
      "1171/2160 done\n",
      "1172/2160 done\n",
      "1173/2160 done\n",
      "1174/2160 done\n",
      "1175/2160 done\n",
      "1176/2160 done\n",
      "1177/2160 done\n",
      "1178/2160 done\n",
      "1179/2160 done\n",
      "1180/2160 done\n",
      "1181/2160 done\n",
      "1182/2160 done\n",
      "1183/2160 done\n",
      "1184/2160 done\n",
      "1185/2160 done\n",
      "1186/2160 done\n",
      "1187/2160 done\n",
      "1188/2160 done\n",
      "1189/2160 done\n",
      "1190/2160 done\n",
      "1191/2160 done\n",
      "1192/2160 done\n",
      "1193/2160 done\n",
      "1194/2160 done\n",
      "1195/2160 done\n",
      "1196/2160 done\n",
      "1197/2160 done\n",
      "1198/2160 done\n",
      "1199/2160 done\n",
      "1200/2160 done\n",
      "1201/2160 done\n",
      "1202/2160 done\n",
      "1203/2160 done\n",
      "1204/2160 done\n",
      "1205/2160 done\n",
      "1206/2160 done\n",
      "1207/2160 done\n",
      "1208/2160 done\n",
      "1209/2160 done\n",
      "1210/2160 done\n",
      "1211/2160 done\n",
      "1212/2160 done\n",
      "1213/2160 done\n",
      "1214/2160 done\n",
      "1215/2160 done\n",
      "1216/2160 done\n",
      "1217/2160 done\n",
      "1218/2160 done\n",
      "1219/2160 done\n",
      "1220/2160 done\n",
      "1221/2160 done\n",
      "1222/2160 done\n",
      "1223/2160 done\n",
      "1224/2160 done\n",
      "1225/2160 done\n",
      "1226/2160 done\n",
      "1227/2160 done\n",
      "1228/2160 done\n",
      "1229/2160 done\n",
      "1230/2160 done\n",
      "1231/2160 done\n",
      "1232/2160 done\n",
      "1233/2160 done\n",
      "1234/2160 done\n",
      "1235/2160 done\n",
      "1236/2160 done\n",
      "1237/2160 done\n",
      "1238/2160 done\n",
      "1239/2160 done\n",
      "1240/2160 done\n",
      "1241/2160 done\n",
      "1242/2160 done\n",
      "1243/2160 done\n",
      "1244/2160 done\n",
      "1245/2160 done\n",
      "1246/2160 done\n",
      "1247/2160 done\n",
      "1248/2160 done\n",
      "1249/2160 done\n",
      "1250/2160 done\n",
      "1251/2160 done\n",
      "1252/2160 done\n",
      "1253/2160 done\n",
      "1254/2160 done\n",
      "1255/2160 done\n",
      "1256/2160 done\n",
      "1257/2160 done\n",
      "1258/2160 done\n",
      "1259/2160 done\n",
      "1260/2160 done\n",
      "1261/2160 done\n",
      "1262/2160 done\n",
      "1263/2160 done\n",
      "1264/2160 done\n",
      "1265/2160 done\n",
      "1266/2160 done\n",
      "1267/2160 done\n",
      "1268/2160 done\n",
      "1269/2160 done\n",
      "1270/2160 done\n",
      "1271/2160 done\n",
      "1272/2160 done\n",
      "1273/2160 done\n",
      "1274/2160 done\n",
      "1275/2160 done\n",
      "1276/2160 done\n",
      "1277/2160 done\n",
      "1278/2160 done\n",
      "1279/2160 done\n",
      "1280/2160 done\n",
      "1281/2160 done\n",
      "1282/2160 done\n",
      "1283/2160 done\n",
      "1284/2160 done\n",
      "1285/2160 done\n",
      "1286/2160 done\n",
      "1287/2160 done\n",
      "1288/2160 done\n",
      "1289/2160 done\n",
      "1290/2160 done\n",
      "1291/2160 done\n",
      "1292/2160 done\n",
      "1293/2160 done\n",
      "1294/2160 done\n",
      "1295/2160 done\n",
      "1296/2160 done\n",
      "1297/2160 done\n",
      "1298/2160 done\n",
      "1299/2160 done\n",
      "1300/2160 done\n",
      "1301/2160 done\n",
      "1302/2160 done\n",
      "1303/2160 done\n",
      "1304/2160 done\n",
      "1305/2160 done\n",
      "1306/2160 done\n",
      "1307/2160 done\n",
      "1308/2160 done\n",
      "1309/2160 done\n",
      "1310/2160 done\n",
      "1311/2160 done\n",
      "1312/2160 done\n",
      "1313/2160 done\n",
      "1314/2160 done\n",
      "1315/2160 done\n",
      "1316/2160 done\n",
      "1317/2160 done\n",
      "1318/2160 done\n",
      "1319/2160 done\n",
      "1320/2160 done\n",
      "1321/2160 done\n",
      "1322/2160 done\n",
      "1323/2160 done\n",
      "1324/2160 done\n",
      "1325/2160 done\n",
      "1326/2160 done\n",
      "1327/2160 done\n",
      "1328/2160 done\n",
      "1329/2160 done\n",
      "1330/2160 done\n",
      "1331/2160 done\n",
      "1332/2160 done\n",
      "1333/2160 done\n",
      "1334/2160 done\n",
      "1335/2160 done\n",
      "1336/2160 done\n",
      "1337/2160 done\n",
      "1338/2160 done\n",
      "1339/2160 done\n",
      "1340/2160 done\n",
      "1341/2160 done\n",
      "1342/2160 done\n",
      "1343/2160 done\n",
      "1344/2160 done\n",
      "1345/2160 done\n",
      "1346/2160 done\n",
      "1347/2160 done\n",
      "1348/2160 done\n",
      "1349/2160 done\n",
      "1350/2160 done\n",
      "1351/2160 done\n",
      "1352/2160 done\n",
      "1353/2160 done\n",
      "1354/2160 done\n",
      "1355/2160 done\n",
      "1356/2160 done\n",
      "1357/2160 done\n",
      "1358/2160 done\n",
      "1359/2160 done\n",
      "1360/2160 done\n",
      "1361/2160 done\n",
      "1362/2160 done\n",
      "1363/2160 done\n",
      "1364/2160 done\n",
      "1365/2160 done\n",
      "1366/2160 done\n",
      "1367/2160 done\n",
      "1368/2160 done\n",
      "1369/2160 done\n",
      "1370/2160 done\n",
      "1371/2160 done\n",
      "1372/2160 done\n",
      "1373/2160 done\n",
      "1374/2160 done\n",
      "1375/2160 done\n",
      "1376/2160 done\n",
      "1377/2160 done\n",
      "1378/2160 done\n",
      "1379/2160 done\n",
      "1380/2160 done\n",
      "1381/2160 done\n",
      "1382/2160 done\n",
      "1383/2160 done\n",
      "1384/2160 done\n",
      "1385/2160 done\n",
      "1386/2160 done\n",
      "1387/2160 done\n",
      "1388/2160 done\n",
      "1389/2160 done\n",
      "1390/2160 done\n",
      "1391/2160 done\n",
      "1392/2160 done\n",
      "1393/2160 done\n",
      "1394/2160 done\n",
      "1395/2160 done\n",
      "1396/2160 done\n",
      "1397/2160 done\n",
      "1398/2160 done\n",
      "1399/2160 done\n",
      "1400/2160 done\n",
      "1401/2160 done\n",
      "1402/2160 done\n",
      "1403/2160 done\n",
      "1404/2160 done\n",
      "1405/2160 done\n",
      "1406/2160 done\n",
      "1407/2160 done\n",
      "1408/2160 done\n",
      "1409/2160 done\n",
      "1410/2160 done\n",
      "1411/2160 done\n",
      "1412/2160 done\n",
      "1413/2160 done\n",
      "1414/2160 done\n",
      "1415/2160 done\n",
      "1416/2160 done\n",
      "1417/2160 done\n",
      "1418/2160 done\n",
      "1419/2160 done\n",
      "1420/2160 done\n",
      "1421/2160 done\n",
      "1422/2160 done\n",
      "1423/2160 done\n",
      "1424/2160 done\n",
      "1425/2160 done\n",
      "1426/2160 done\n",
      "1427/2160 done\n",
      "1428/2160 done\n",
      "1429/2160 done\n",
      "1430/2160 done\n",
      "1431/2160 done\n",
      "1432/2160 done\n",
      "1433/2160 done\n",
      "1434/2160 done\n",
      "1435/2160 done\n",
      "1436/2160 done\n",
      "1437/2160 done\n",
      "1438/2160 done\n",
      "1439/2160 done\n",
      "1440/2160 done\n",
      "1441/2160 done\n",
      "1442/2160 done\n",
      "1443/2160 done\n",
      "1444/2160 done\n",
      "1445/2160 done\n",
      "1446/2160 done\n",
      "1447/2160 done\n",
      "1448/2160 done\n",
      "1449/2160 done\n",
      "1450/2160 done\n",
      "1451/2160 done\n",
      "1452/2160 done\n",
      "1453/2160 done\n",
      "1454/2160 done\n",
      "1455/2160 done\n",
      "1456/2160 done\n",
      "1457/2160 done\n",
      "1458/2160 done\n",
      "1459/2160 done\n",
      "1460/2160 done\n",
      "1461/2160 done\n",
      "1462/2160 done\n",
      "1463/2160 done\n",
      "1464/2160 done\n",
      "1465/2160 done\n",
      "1466/2160 done\n",
      "1467/2160 done\n",
      "1468/2160 done\n",
      "1469/2160 done\n",
      "1470/2160 done\n",
      "1471/2160 done\n",
      "1472/2160 done\n",
      "1473/2160 done\n",
      "1474/2160 done\n",
      "1475/2160 done\n",
      "1476/2160 done\n",
      "1477/2160 done\n",
      "1478/2160 done\n",
      "1479/2160 done\n",
      "1480/2160 done\n",
      "1481/2160 done\n",
      "1482/2160 done\n",
      "1483/2160 done\n",
      "1484/2160 done\n",
      "1485/2160 done\n",
      "1486/2160 done\n",
      "1487/2160 done\n",
      "1488/2160 done\n",
      "1489/2160 done\n",
      "1490/2160 done\n",
      "1491/2160 done\n",
      "1492/2160 done\n",
      "1493/2160 done\n",
      "1494/2160 done\n",
      "1495/2160 done\n",
      "1496/2160 done\n",
      "1497/2160 done\n",
      "1498/2160 done\n",
      "1499/2160 done\n",
      "1500/2160 done\n",
      "1501/2160 done\n",
      "1502/2160 done\n",
      "1503/2160 done\n",
      "1504/2160 done\n",
      "1505/2160 done\n",
      "1506/2160 done\n",
      "1507/2160 done\n",
      "1508/2160 done\n",
      "1509/2160 done\n",
      "1510/2160 done\n",
      "1511/2160 done\n",
      "1512/2160 done\n",
      "1513/2160 done\n",
      "1514/2160 done\n",
      "1515/2160 done\n",
      "1516/2160 done\n",
      "1517/2160 done\n",
      "1518/2160 done\n",
      "1519/2160 done\n",
      "1520/2160 done\n",
      "1521/2160 done\n",
      "1522/2160 done\n",
      "1523/2160 done\n",
      "1524/2160 done\n",
      "1525/2160 done\n",
      "1526/2160 done\n",
      "1527/2160 done\n",
      "1528/2160 done\n",
      "1529/2160 done\n",
      "1530/2160 done\n",
      "1531/2160 done\n",
      "1532/2160 done\n",
      "1533/2160 done\n",
      "1534/2160 done\n",
      "1535/2160 done\n",
      "1536/2160 done\n",
      "1537/2160 done\n",
      "1538/2160 done\n",
      "1539/2160 done\n",
      "1540/2160 done\n",
      "1541/2160 done\n",
      "1542/2160 done\n",
      "1543/2160 done\n",
      "1544/2160 done\n",
      "1545/2160 done\n",
      "1546/2160 done\n",
      "1547/2160 done\n",
      "1548/2160 done\n",
      "1549/2160 done\n",
      "1550/2160 done\n",
      "1551/2160 done\n",
      "1552/2160 done\n",
      "1553/2160 done\n",
      "1554/2160 done\n",
      "1555/2160 done\n",
      "1556/2160 done\n",
      "1557/2160 done\n",
      "1558/2160 done\n",
      "1559/2160 done\n",
      "1560/2160 done\n",
      "1561/2160 done\n",
      "1562/2160 done\n",
      "1563/2160 done\n",
      "1564/2160 done\n",
      "1565/2160 done\n",
      "1566/2160 done\n",
      "1567/2160 done\n",
      "1568/2160 done\n",
      "1569/2160 done\n",
      "1570/2160 done\n",
      "1571/2160 done\n",
      "1572/2160 done\n",
      "1573/2160 done\n",
      "1574/2160 done\n",
      "1575/2160 done\n",
      "1576/2160 done\n",
      "1577/2160 done\n",
      "1578/2160 done\n",
      "1579/2160 done\n",
      "1580/2160 done\n",
      "1581/2160 done\n",
      "1582/2160 done\n",
      "1583/2160 done\n",
      "1584/2160 done\n",
      "1585/2160 done\n",
      "1586/2160 done\n",
      "1587/2160 done\n",
      "1588/2160 done\n",
      "1589/2160 done\n",
      "1590/2160 done\n",
      "1591/2160 done\n",
      "1592/2160 done\n",
      "1593/2160 done\n",
      "1594/2160 done\n",
      "1595/2160 done\n",
      "1596/2160 done\n",
      "1597/2160 done\n",
      "1598/2160 done\n",
      "1599/2160 done\n",
      "1600/2160 done\n",
      "1601/2160 done\n",
      "1602/2160 done\n",
      "1603/2160 done\n",
      "1604/2160 done\n",
      "1605/2160 done\n",
      "1606/2160 done\n",
      "1607/2160 done\n",
      "1608/2160 done\n",
      "1609/2160 done\n",
      "1610/2160 done\n",
      "1611/2160 done\n",
      "1612/2160 done\n",
      "1613/2160 done\n",
      "1614/2160 done\n",
      "1615/2160 done\n",
      "1616/2160 done\n",
      "1617/2160 done\n",
      "1618/2160 done\n",
      "1619/2160 done\n",
      "1620/2160 done\n",
      "1621/2160 done\n",
      "1622/2160 done\n",
      "1623/2160 done\n",
      "1624/2160 done\n",
      "1625/2160 done\n",
      "1626/2160 done\n",
      "1627/2160 done\n",
      "1628/2160 done\n",
      "1629/2160 done\n",
      "1630/2160 done\n",
      "1631/2160 done\n",
      "1632/2160 done\n",
      "1633/2160 done\n",
      "1634/2160 done\n",
      "1635/2160 done\n",
      "1636/2160 done\n",
      "1637/2160 done\n",
      "1638/2160 done\n",
      "1639/2160 done\n",
      "1640/2160 done\n",
      "1641/2160 done\n",
      "1642/2160 done\n",
      "1643/2160 done\n",
      "1644/2160 done\n",
      "1645/2160 done\n",
      "1646/2160 done\n",
      "1647/2160 done\n",
      "1648/2160 done\n",
      "1649/2160 done\n",
      "1650/2160 done\n",
      "1651/2160 done\n",
      "1652/2160 done\n",
      "1653/2160 done\n",
      "1654/2160 done\n",
      "1655/2160 done\n",
      "1656/2160 done\n",
      "1657/2160 done\n",
      "1658/2160 done\n",
      "1659/2160 done\n",
      "1660/2160 done\n",
      "1661/2160 done\n",
      "1662/2160 done\n",
      "1663/2160 done\n",
      "1664/2160 done\n",
      "1665/2160 done\n",
      "1666/2160 done\n",
      "1667/2160 done\n",
      "1668/2160 done\n",
      "1669/2160 done\n",
      "1670/2160 done\n",
      "1671/2160 done\n",
      "1672/2160 done\n",
      "1673/2160 done\n",
      "1674/2160 done\n",
      "1675/2160 done\n",
      "1676/2160 done\n",
      "1677/2160 done\n",
      "1678/2160 done\n",
      "1679/2160 done\n",
      "1680/2160 done\n",
      "1681/2160 done\n",
      "1682/2160 done\n",
      "1683/2160 done\n",
      "1684/2160 done\n",
      "1685/2160 done\n",
      "1686/2160 done\n",
      "1687/2160 done\n",
      "1688/2160 done\n",
      "1689/2160 done\n",
      "1690/2160 done\n",
      "1691/2160 done\n",
      "1692/2160 done\n",
      "1693/2160 done\n",
      "1694/2160 done\n",
      "1695/2160 done\n",
      "1696/2160 done\n",
      "1697/2160 done\n",
      "1698/2160 done\n",
      "1699/2160 done\n",
      "1700/2160 done\n",
      "1701/2160 done\n",
      "1702/2160 done\n",
      "1703/2160 done\n",
      "1704/2160 done\n",
      "1705/2160 done\n",
      "1706/2160 done\n",
      "1707/2160 done\n",
      "1708/2160 done\n",
      "1709/2160 done\n",
      "1710/2160 done\n",
      "1711/2160 done\n",
      "1712/2160 done\n",
      "1713/2160 done\n",
      "1714/2160 done\n",
      "1715/2160 done\n",
      "1716/2160 done\n",
      "1717/2160 done\n",
      "1718/2160 done\n",
      "1719/2160 done\n",
      "1720/2160 done\n",
      "1721/2160 done\n",
      "1722/2160 done\n",
      "1723/2160 done\n",
      "1724/2160 done\n",
      "1725/2160 done\n",
      "1726/2160 done\n",
      "1727/2160 done\n",
      "1728/2160 done\n",
      "1729/2160 done\n",
      "1730/2160 done\n",
      "1731/2160 done\n",
      "1732/2160 done\n",
      "1733/2160 done\n",
      "1734/2160 done\n",
      "1735/2160 done\n",
      "1736/2160 done\n",
      "1737/2160 done\n",
      "1738/2160 done\n",
      "1739/2160 done\n",
      "1740/2160 done\n",
      "1741/2160 done\n",
      "1742/2160 done\n",
      "1743/2160 done\n",
      "1744/2160 done\n",
      "1745/2160 done\n",
      "1746/2160 done\n",
      "1747/2160 done\n",
      "1748/2160 done\n",
      "1749/2160 done\n",
      "1750/2160 done\n",
      "1751/2160 done\n",
      "1752/2160 done\n",
      "1753/2160 done\n",
      "1754/2160 done\n",
      "1755/2160 done\n",
      "1756/2160 done\n",
      "1757/2160 done\n",
      "1758/2160 done\n",
      "1759/2160 done\n",
      "1760/2160 done\n",
      "1761/2160 done\n",
      "1762/2160 done\n",
      "1763/2160 done\n",
      "1764/2160 done\n",
      "1765/2160 done\n",
      "1766/2160 done\n",
      "1767/2160 done\n",
      "1768/2160 done\n",
      "1769/2160 done\n",
      "1770/2160 done\n",
      "1771/2160 done\n",
      "1772/2160 done\n",
      "1773/2160 done\n",
      "1774/2160 done\n",
      "1775/2160 done\n",
      "1776/2160 done\n",
      "1777/2160 done\n",
      "1778/2160 done\n",
      "1779/2160 done\n",
      "1780/2160 done\n",
      "1781/2160 done\n",
      "1782/2160 done\n",
      "1783/2160 done\n",
      "1784/2160 done\n",
      "1785/2160 done\n",
      "1786/2160 done\n",
      "1787/2160 done\n",
      "1788/2160 done\n",
      "1789/2160 done\n",
      "1790/2160 done\n",
      "1791/2160 done\n",
      "1792/2160 done\n",
      "1793/2160 done\n",
      "1794/2160 done\n",
      "1795/2160 done\n",
      "1796/2160 done\n",
      "1797/2160 done\n",
      "1798/2160 done\n",
      "1799/2160 done\n",
      "1800/2160 done\n",
      "1801/2160 done\n",
      "1802/2160 done\n",
      "1803/2160 done\n",
      "1804/2160 done\n",
      "1805/2160 done\n",
      "1806/2160 done\n",
      "1807/2160 done\n",
      "1808/2160 done\n",
      "1809/2160 done\n",
      "1810/2160 done\n",
      "1811/2160 done\n",
      "1812/2160 done\n",
      "1813/2160 done\n",
      "1814/2160 done\n",
      "1815/2160 done\n",
      "1816/2160 done\n",
      "1817/2160 done\n",
      "1818/2160 done\n",
      "1819/2160 done\n",
      "1820/2160 done\n",
      "1821/2160 done\n",
      "1822/2160 done\n",
      "1823/2160 done\n",
      "1824/2160 done\n",
      "1825/2160 done\n",
      "1826/2160 done\n",
      "1827/2160 done\n",
      "1828/2160 done\n",
      "1829/2160 done\n",
      "1830/2160 done\n",
      "1831/2160 done\n",
      "1832/2160 done\n",
      "1833/2160 done\n",
      "1834/2160 done\n",
      "1835/2160 done\n",
      "1836/2160 done\n",
      "1837/2160 done\n",
      "1838/2160 done\n",
      "1839/2160 done\n",
      "1840/2160 done\n",
      "1841/2160 done\n",
      "1842/2160 done\n",
      "1843/2160 done\n",
      "1844/2160 done\n",
      "1845/2160 done\n",
      "1846/2160 done\n",
      "1847/2160 done\n",
      "1848/2160 done\n",
      "1849/2160 done\n",
      "1850/2160 done\n",
      "1851/2160 done\n",
      "1852/2160 done\n",
      "1853/2160 done\n",
      "1854/2160 done\n",
      "1855/2160 done\n",
      "1856/2160 done\n",
      "1857/2160 done\n",
      "1858/2160 done\n",
      "1859/2160 done\n",
      "1860/2160 done\n",
      "1861/2160 done\n",
      "1862/2160 done\n",
      "1863/2160 done\n",
      "1864/2160 done\n",
      "1865/2160 done\n",
      "1866/2160 done\n",
      "1867/2160 done\n",
      "1868/2160 done\n",
      "1869/2160 done\n",
      "1870/2160 done\n",
      "1871/2160 done\n",
      "1872/2160 done\n",
      "1873/2160 done\n",
      "1874/2160 done\n",
      "1875/2160 done\n",
      "1876/2160 done\n",
      "1877/2160 done\n",
      "1878/2160 done\n",
      "1879/2160 done\n",
      "1880/2160 done\n",
      "1881/2160 done\n",
      "1882/2160 done\n",
      "1883/2160 done\n",
      "1884/2160 done\n",
      "1885/2160 done\n",
      "1886/2160 done\n",
      "1887/2160 done\n",
      "1888/2160 done\n",
      "1889/2160 done\n",
      "1890/2160 done\n",
      "1891/2160 done\n",
      "1892/2160 done\n",
      "1893/2160 done\n",
      "1894/2160 done\n",
      "1895/2160 done\n",
      "1896/2160 done\n",
      "1897/2160 done\n",
      "1898/2160 done\n",
      "1899/2160 done\n",
      "1900/2160 done\n",
      "1901/2160 done\n",
      "1902/2160 done\n",
      "1903/2160 done\n",
      "1904/2160 done\n",
      "1905/2160 done\n",
      "1906/2160 done\n",
      "1907/2160 done\n",
      "1908/2160 done\n",
      "1909/2160 done\n",
      "1910/2160 done\n",
      "1911/2160 done\n",
      "1912/2160 done\n",
      "1913/2160 done\n",
      "1914/2160 done\n",
      "1915/2160 done\n",
      "1916/2160 done\n",
      "1917/2160 done\n",
      "1918/2160 done\n",
      "1919/2160 done\n",
      "1920/2160 done\n",
      "1921/2160 done\n",
      "1922/2160 done\n",
      "1923/2160 done\n",
      "1924/2160 done\n",
      "1925/2160 done\n",
      "1926/2160 done\n",
      "1927/2160 done\n",
      "1928/2160 done\n",
      "1929/2160 done\n",
      "1930/2160 done\n",
      "1931/2160 done\n",
      "1932/2160 done\n",
      "1933/2160 done\n",
      "1934/2160 done\n",
      "1935/2160 done\n",
      "1936/2160 done\n",
      "1937/2160 done\n",
      "1938/2160 done\n",
      "1939/2160 done\n",
      "1940/2160 done\n",
      "1941/2160 done\n",
      "1942/2160 done\n",
      "1943/2160 done\n",
      "1944/2160 done\n",
      "1945/2160 done\n",
      "1946/2160 done\n",
      "1947/2160 done\n",
      "1948/2160 done\n",
      "1949/2160 done\n",
      "1950/2160 done\n",
      "1951/2160 done\n",
      "1952/2160 skipped\n",
      "1953/2160 done\n",
      "1954/2160 done\n",
      "1955/2160 done\n",
      "1956/2160 done\n",
      "1957/2160 done\n",
      "1958/2160 done\n",
      "1959/2160 skipped\n",
      "1960/2160 skipped\n",
      "1961/2160 skipped\n",
      "1962/2160 skipped\n",
      "1963/2160 skipped\n",
      "1964/2160 skipped\n",
      "1965/2160 skipped\n",
      "1966/2160 skipped\n",
      "1967/2160 skipped\n",
      "1968/2160 skipped\n",
      "1969/2160 skipped\n",
      "1970/2160 skipped\n",
      "1971/2160 skipped\n",
      "1972/2160 skipped\n",
      "1973/2160 skipped\n",
      "1974/2160 skipped\n",
      "1975/2160 skipped\n",
      "1976/2160 skipped\n",
      "1977/2160 skipped\n",
      "1978/2160 skipped\n",
      "1979/2160 skipped\n",
      "1980/2160 skipped\n",
      "1981/2160 skipped\n",
      "1982/2160 skipped\n",
      "1983/2160 skipped\n",
      "1984/2160 skipped\n",
      "1985/2160 skipped\n",
      "1986/2160 skipped\n",
      "1987/2160 skipped\n",
      "1988/2160 skipped\n",
      "1989/2160 skipped\n",
      "1990/2160 skipped\n",
      "1991/2160 skipped\n",
      "1992/2160 skipped\n",
      "1993/2160 skipped\n",
      "1994/2160 skipped\n",
      "1995/2160 skipped\n",
      "1996/2160 skipped\n",
      "1997/2160 skipped\n",
      "1998/2160 skipped\n",
      "1999/2160 skipped\n",
      "2000/2160 skipped\n",
      "2001/2160 skipped\n",
      "2002/2160 skipped\n",
      "2003/2160 skipped\n",
      "2004/2160 skipped\n",
      "2005/2160 skipped\n",
      "2006/2160 skipped\n",
      "2007/2160 skipped\n",
      "2008/2160 skipped\n",
      "2009/2160 skipped\n",
      "2010/2160 skipped\n",
      "2011/2160 skipped\n",
      "2012/2160 skipped\n",
      "2013/2160 skipped\n",
      "2014/2160 skipped\n",
      "2015/2160 skipped\n",
      "2016/2160 skipped\n",
      "2017/2160 skipped\n",
      "2018/2160 skipped\n",
      "2019/2160 skipped\n",
      "2020/2160 skipped\n",
      "2021/2160 skipped\n",
      "2022/2160 skipped\n",
      "2023/2160 skipped\n",
      "2024/2160 skipped\n",
      "2025/2160 skipped\n",
      "2026/2160 skipped\n",
      "2027/2160 skipped\n",
      "2028/2160 skipped\n",
      "2029/2160 skipped\n",
      "2030/2160 skipped\n",
      "2031/2160 skipped\n",
      "2032/2160 skipped\n",
      "2033/2160 skipped\n",
      "2034/2160 skipped\n",
      "2035/2160 skipped\n",
      "2036/2160 skipped\n",
      "2037/2160 skipped\n",
      "2038/2160 skipped\n",
      "2039/2160 skipped\n",
      "2040/2160 skipped\n",
      "2041/2160 skipped\n",
      "2042/2160 skipped\n",
      "2043/2160 skipped\n",
      "2044/2160 skipped\n",
      "2045/2160 skipped\n",
      "2046/2160 skipped\n",
      "2047/2160 skipped\n",
      "2048/2160 skipped\n",
      "2049/2160 skipped\n",
      "2050/2160 skipped\n",
      "2051/2160 skipped\n",
      "2052/2160 skipped\n",
      "2053/2160 skipped\n",
      "2054/2160 skipped\n",
      "2055/2160 skipped\n",
      "2056/2160 skipped\n",
      "2057/2160 skipped\n",
      "2058/2160 skipped\n",
      "2059/2160 skipped\n",
      "2060/2160 skipped\n",
      "2061/2160 skipped\n",
      "2062/2160 skipped\n",
      "2063/2160 skipped\n",
      "2064/2160 skipped\n",
      "2065/2160 skipped\n",
      "2066/2160 skipped\n",
      "2067/2160 skipped\n",
      "2068/2160 skipped\n",
      "2069/2160 skipped\n",
      "2070/2160 skipped\n",
      "2071/2160 skipped\n",
      "2072/2160 skipped\n",
      "2073/2160 skipped\n",
      "2074/2160 skipped\n",
      "2075/2160 skipped\n",
      "2076/2160 skipped\n",
      "2077/2160 skipped\n",
      "2078/2160 skipped\n",
      "2079/2160 skipped\n",
      "2080/2160 skipped\n",
      "2081/2160 skipped\n",
      "2082/2160 skipped\n",
      "2083/2160 skipped\n",
      "2084/2160 skipped\n",
      "2085/2160 skipped\n",
      "2086/2160 skipped\n",
      "2087/2160 skipped\n",
      "2088/2160 skipped\n",
      "2089/2160 skipped\n",
      "2090/2160 skipped\n",
      "2091/2160 skipped\n",
      "2092/2160 skipped\n",
      "2093/2160 skipped\n",
      "2094/2160 skipped\n",
      "2095/2160 skipped\n",
      "2096/2160 skipped\n",
      "2097/2160 skipped\n",
      "2098/2160 skipped\n",
      "2099/2160 skipped\n",
      "2100/2160 skipped\n",
      "2101/2160 skipped\n",
      "2102/2160 skipped\n",
      "2103/2160 skipped\n",
      "2104/2160 skipped\n",
      "2105/2160 skipped\n",
      "2106/2160 skipped\n",
      "2107/2160 skipped\n",
      "2108/2160 skipped\n",
      "2109/2160 skipped\n",
      "2110/2160 skipped\n",
      "2111/2160 skipped\n",
      "2112/2160 skipped\n",
      "2113/2160 skipped\n",
      "2114/2160 skipped\n",
      "2115/2160 skipped\n",
      "2116/2160 skipped\n",
      "2117/2160 skipped\n",
      "2118/2160 skipped\n",
      "2119/2160 skipped\n",
      "2120/2160 skipped\n",
      "2121/2160 skipped\n",
      "2122/2160 skipped\n",
      "2123/2160 skipped\n",
      "2124/2160 skipped\n",
      "2125/2160 skipped\n",
      "2126/2160 skipped\n",
      "2127/2160 skipped\n",
      "2128/2160 skipped\n",
      "2129/2160 skipped\n",
      "2130/2160 skipped\n",
      "2131/2160 skipped\n",
      "2132/2160 skipped\n",
      "2133/2160 skipped\n",
      "2134/2160 skipped\n",
      "2135/2160 skipped\n",
      "2136/2160 skipped\n",
      "2137/2160 skipped\n",
      "2138/2160 skipped\n",
      "2139/2160 skipped\n",
      "2140/2160 skipped\n",
      "2141/2160 skipped\n",
      "2142/2160 skipped\n",
      "2143/2160 skipped\n",
      "2144/2160 skipped\n",
      "2145/2160 skipped\n",
      "2146/2160 skipped\n",
      "2147/2160 skipped\n",
      "2148/2160 skipped\n",
      "2149/2160 skipped\n",
      "2150/2160 skipped\n",
      "2151/2160 skipped\n",
      "2152/2160 skipped\n",
      "2153/2160 skipped\n",
      "2154/2160 skipped\n",
      "2155/2160 skipped\n",
      "2156/2160 skipped\n",
      "2157/2160 skipped\n",
      "2158/2160 skipped\n",
      "2159/2160 skipped\n",
      "2160/2160 skipped\n"
     ]
    }
   ],
   "source": [
    "main_base_df_list = []\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Worker wrapper for safe execution\n",
    "def safe_fetch(ticker):\n",
    "    try:\n",
    "        return data_fetch_feature_generation(ticker)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {ticker}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Run in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    results = list(executor.map(safe_fetch, tickers_ns))\n",
    "\n",
    "# Collect results\n",
    "for i, (df_fetch, X_fetch, y_fetch) in enumerate(results, start=1):\n",
    "    if df_fetch is None or X_fetch is None or y_fetch is None:\n",
    "        print(f\"{i}/{len(tickers_ns)} skipped\")\n",
    "        continue\n",
    "    main_base_df_list.append(df_fetch)\n",
    "    X_list.append(X_fetch)\n",
    "    y_list.append(y_fetch)\n",
    "    print(f\"{i}/{len(tickers_ns)} done\")\n",
    "\n",
    "# Concatenate once\n",
    "main_base_df = pd.concat(main_base_df_list, axis=0).reset_index(drop=True)\n",
    "X = pd.concat(X_list, axis=0).reset_index(drop=True)\n",
    "y = pd.concat(y_list, axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c51c869",
   "metadata": {},
   "source": [
    "#### Summary for above code cells\n",
    "* We first made a function that fetchs stock historical prices of stocks and creats more features.\n",
    "* The we difined a list containing 1000+ tickers listed on NSE.\n",
    "* THe using for loop and concurrent tool which fetchs all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfda0b",
   "metadata": {},
   "source": [
    "### **2.2 --> Model building for best to find algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198f2cd",
   "metadata": {},
   "source": [
    "#### 2.21 Segregating feature as num and cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521e89d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features :  ['sector', 'day_of_week', 'ticker']\n",
      "Numerical Features :  ['return_1d', 'return_7d', 'return_30d', 'return_180d', 'return_365d', 'stoch', 'roc', 'williams_r', 'realized_vol_5', 'rolling_std_5', 'rolling_skew_5', 'rolling_kurt_5', 'rsi', 'macd', 'sma5', 'Volume', 'sma10', 'sma20', 'sma50', 'sma100', 'sma200', 'vwap', 'volume_change']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "num_cols = []\n",
    "for i in X.columns:\n",
    "    if X[i].dtype == \"O\":\n",
    "        cat_cols.append(i)\n",
    "    else:\n",
    "        num_cols.append(i)\n",
    "print(\"Categorical Features : \", cat_cols)\n",
    "print(\"Numerical Features : \", num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce705d",
   "metadata": {},
   "source": [
    "#### Feature Summary\n",
    "\n",
    "- **Categorical Features**  \n",
    "  - `sector`: Represents the industry/sector classification of the stock.  \n",
    "\n",
    "- **Numerical Features**  \n",
    "  - `return_1d`: Daily return of the stock.  \n",
    "  - `return_5d`: Return over the last 5 days.  \n",
    "  - `return_10d`: Return over the last 10 days.  \n",
    "  - `stoch`: Stochastic oscillator value, measures momentum.  \n",
    "  - `roc`: Rate of Change, shows percentage change over a period.  \n",
    "  - `williams_r`: Williams %R, momentum indicator for overbought/oversold conditions.  \n",
    "  - `realized_vol_5`: Realized volatility over the last 5 days.  \n",
    "  - `rolling_std_5`: Rolling standard deviation (5-day window).  \n",
    "  - `rolling_skew_5`: Rolling skewness (5-day window).  \n",
    "  - `rolling_kurt_5`: Rolling kurtosis (5-day window).  \n",
    "  - `rsi`: Relative Strength Index, momentum-based indicator.  \n",
    "  - `macd`: Moving Average Convergence Divergence, trend/momentum indicator.  \n",
    "  - `sma5`: Simple Moving Average (5-day).  \n",
    "  - `Volume`: Trading volume of the stock.  \n",
    "  - `sma10`: Simple Moving Average (10-day).  \n",
    "  - `sma20`: Simple Moving Average (20-day).  \n",
    "  - `sma50`: Simple Moving Average (50-day).  \n",
    "  - `sma100`: Simple Moving Average (100-day).  \n",
    "  - `sma200`: Simple Moving Average (200-day).  \n",
    "  - `obv`: On-Balance Volume, combines price and volume for trend signals.  \n",
    "  - `vwap`: Volume Weighted Average Price.  \n",
    "  - `volume_change`: Change in trading volume compared to previous periods.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1c5af",
   "metadata": {},
   "source": [
    "#### 2.22 building models without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c15acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X, y, num_cols, cat_cols, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Train multiple classification models with preprocessing pipeline\n",
    "    and print accuracy + classification report for each.\n",
    "    \"\"\"\n",
    "    # Numeric columns\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.dropna()   # drop rows where any feature is NaN (was inf before)\n",
    "\n",
    "    # Also align y with X (important!)\n",
    "    y = y.loc[X.index]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), num_cols),\n",
    "            (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "        \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "        \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=random_state),\n",
    "        \"LightGBM\": LGBMClassifier(random_state=random_state),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "    }\n",
    "\n",
    "    # Train & evaluate\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", model)\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        print(f\"\\n====== {name} ======\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c09562a",
   "metadata": {},
   "source": [
    "#### Function Summary: `train_and_evaluate_models`\n",
    "\n",
    "- **Purpose**  \n",
    "  - Trains multiple classification models on given dataset.  \n",
    "  - Handles preprocessing for numerical and categorical features.  \n",
    "  - Evaluates models using accuracy and classification report.  \n",
    "\n",
    "- **Preprocessing Steps**  \n",
    "  - Replace infinite values (`inf`, `-inf`) with NaN.  \n",
    "  - Drop rows with missing values.  \n",
    "  - Align target `y` with filtered features `X`.  \n",
    "  - Split data into train and test sets (stratified).  \n",
    "  - Scale numerical features using `StandardScaler`.  \n",
    "  - Encode categorical features using `OrdinalEncoder` with unknown handling.  \n",
    "\n",
    "- **Models Trained**  \n",
    "  - Logistic Regression  \n",
    "  - Decision Tree Classifier  \n",
    "  - Gaussian Naive Bayes  \n",
    "  - AdaBoost Classifier  \n",
    "  - XGBoost Classifier  \n",
    "  - LightGBM Classifier  \n",
    "  - CatBoost Classifier  \n",
    "\n",
    "- **Evaluation Output**  \n",
    "  - For each model, prints:  \n",
    "    - Model name  \n",
    "    - Accuracy score on test data  \n",
    "    - Detailed classification report (precision, recall, F1-score, support)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154f44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Logistic Regression ======\n",
      "Accuracy: 0.5381748454836548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69    143875\n",
      "           1       0.52      0.06      0.10    124705\n",
      "\n",
      "    accuracy                           0.54    268580\n",
      "   macro avg       0.53      0.51      0.40    268580\n",
      "weighted avg       0.53      0.54      0.42    268580\n",
      "\n",
      "\n",
      "====== DecisionTreeClassifier ======\n",
      "Accuracy: 0.5198339414699531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55    143875\n",
      "           1       0.48      0.49      0.48    124705\n",
      "\n",
      "    accuracy                           0.52    268580\n",
      "   macro avg       0.52      0.52      0.52    268580\n",
      "weighted avg       0.52      0.52      0.52    268580\n",
      "\n",
      "\n",
      "====== GaussianNB ======\n",
      "Accuracy: 0.5237173281703775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.64    143875\n",
      "           1       0.47      0.22      0.30    124705\n",
      "\n",
      "    accuracy                           0.52    268580\n",
      "   macro avg       0.51      0.50      0.47    268580\n",
      "weighted avg       0.51      0.52      0.48    268580\n",
      "\n",
      "\n",
      "====== AdaBoostClassifier ======\n",
      "Accuracy: 0.5455097177749646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.69    143875\n",
      "           1       0.56      0.10      0.17    124705\n",
      "\n",
      "    accuracy                           0.55    268580\n",
      "   macro avg       0.55      0.52      0.43    268580\n",
      "weighted avg       0.55      0.55      0.45    268580\n",
      "\n",
      "\n",
      "====== XGBoost ======\n",
      "Accuracy: 0.5680691041775262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.79      0.66    143875\n",
      "           1       0.56      0.32      0.41    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.57      0.55      0.53    268580\n",
      "weighted avg       0.57      0.57      0.54    268580\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 498817, number of negative: 575499\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6138\n",
      "[LightGBM] [Info] Number of data points in the train set: 1074316, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464311 -> initscore=-0.142998\n",
      "[LightGBM] [Info] Start training from score -0.142998\n",
      "\n",
      "====== LightGBM ======\n",
      "Accuracy: 0.5651053689775858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.84      0.67    143875\n",
      "           1       0.57      0.25      0.35    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.57      0.54      0.51    268580\n",
      "weighted avg       0.57      0.57      0.52    268580\n",
      "\n",
      "\n",
      "====== CatBoost ======\n",
      "Accuracy: 0.5692977883684563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.76      0.65    143875\n",
      "           1       0.56      0.35      0.43    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.57      0.55      0.54    268580\n",
      "weighted avg       0.57      0.57      0.55    268580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_models(X, y, num_cols, cat_cols) # trigger the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb040da4",
   "metadata": {},
   "source": [
    "#### Model Evaluation Summary\n",
    "\n",
    "- **Logistic Regression**\n",
    "  - Accuracy: **0.54**\n",
    "  - Class 0: High recall (0.96), but Class 1 recall is very poor (0.06).\n",
    "  - Imbalanced performance, favors majority class.\n",
    "  - Also precision is low overall. But is acceptable for this data.\n",
    "\n",
    "- **Decision Tree Classifier**\n",
    "  - Accuracy: **0.52**\n",
    "  - Balanced precision/recall for both classes (~0.5).\n",
    "  - No strong advantage over baseline.\n",
    "\n",
    "- **Gaussian Naive Bayes**\n",
    "  - Accuracy: **0.52**\n",
    "  - Class 1 recall is decent (0.79), but Class 0 recall is very poor (0.22).\n",
    "  - Produces unbalanced predictions.\n",
    "\n",
    "- **AdaBoost Classifier**\n",
    "  - Accuracy: **0.54**\n",
    "  - Good recall for Class 0 (0.94), but weak recall for Class 1 (0.09).\n",
    "  - Skews toward majority class.\n",
    "\n",
    "- **XGBoost**\n",
    "  - Accuracy: **0.57**\n",
    "  - Better balance: Class 0 recall (0.79), Class 1 recall (0.32).\n",
    "  - Improved overall f1-scores compared to simpler models.\n",
    "\n",
    "- **LightGBM**\n",
    "  - Accuracy: **0.56**\n",
    "  - Strong Class 0 recall (0.84), weak Class 1 recall (0.25).\n",
    "  - Skewed toward negative class but slightly better than AdaBoost.\n",
    "\n",
    "- **CatBoost**\n",
    "  - Accuracy: **0.57**\n",
    "  - Class 0 recall (0.76), Class 1 recall (0.35).\n",
    "  - More balanced than LightGBM and AdaBoost.\n",
    "\n",
    "---\n",
    "\n",
    "**Overall Insights**  \n",
    "- Tree-based boosting models (**XGBoost, LightGBM, CatBoost**) perform best (~0.56 accuracy).  \n",
    "- Simpler models (**Logistic Regression, Decision Tree, GaussianNB**) show weaker balance between classes.  \n",
    "- Class imbalance is a major issue — models tend to favor Class 0 heavily.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a37ed",
   "metadata": {},
   "source": [
    "### **2.3 --> Hyper Tuning the Model will be very expensive so we will try stacking for best Model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67be70a",
   "metadata": {},
   "source": [
    "#### 2.31 Splitting data in training and test data and handling nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "362ebda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.dropna()   # drop rows where any feature is NaN (was inf before)\n",
    "\n",
    "# Also align y with X (important!)\n",
    "y = y.loc[X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fa7ec",
   "metadata": {},
   "source": [
    "#### 2.32 We will be Stacking CatBosst, LightGBM and XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937e9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 498817, number of negative: 575499\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.781673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6138\n",
      "[LightGBM] [Info] Number of data points in the train set: 1074316, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464311 -> initscore=-0.142998\n",
      "[LightGBM] [Info] Start training from score -0.142998\n",
      "[LightGBM] [Info] Number of positive: 399053, number of negative: 460399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.401236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6138\n",
      "[LightGBM] [Info] Number of data points in the train set: 859452, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464311 -> initscore=-0.142999\n",
      "[LightGBM] [Info] Start training from score -0.142999\n",
      "[LightGBM] [Info] Number of positive: 399053, number of negative: 460400\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.420698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6138\n",
      "[LightGBM] [Info] Number of data points in the train set: 859453, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464310 -> initscore=-0.143001\n",
      "[LightGBM] [Info] Start training from score -0.143001\n",
      "[LightGBM] [Info] Number of positive: 399054, number of negative: 460399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.379492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6138\n",
      "[LightGBM] [Info] Number of data points in the train set: 859453, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464312 -> initscore=-0.142997\n",
      "[LightGBM] [Info] Start training from score -0.142997\n",
      "[LightGBM] [Info] Number of positive: 399054, number of negative: 460399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.375970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6138\n",
      "[LightGBM] [Info] Number of data points in the train set: 859453, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464312 -> initscore=-0.142997\n",
      "[LightGBM] [Info] Start training from score -0.142997\n",
      "[LightGBM] [Info] Number of positive: 399054, number of negative: 460399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.332962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6138\n",
      "[LightGBM] [Info] Number of data points in the train set: 859453, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464312 -> initscore=-0.142997\n",
      "[LightGBM] [Info] Start training from score -0.142997\n",
      "Stacked Model Accuracy: 0.570988159952342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.77      0.66    143875\n",
      "           1       0.56      0.34      0.42    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.57      0.56      0.54    268580\n",
      "weighted avg       0.57      0.57      0.55    268580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def stack_models(X, y, num_cols, cat_cols, test_size=0.2, random_state=42):\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), num_cols),\n",
    "            (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Base models\n",
    "    base_models = [\n",
    "        (\"xgb\", XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=random_state)),\n",
    "        (\"lgbm\", LGBMClassifier(random_state=random_state)),\n",
    "        (\"cat\", CatBoostClassifier(verbose=0, random_state=random_state))\n",
    "    ]\n",
    "\n",
    "    # Meta-model\n",
    "    meta_model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    # Stacking Classifier\n",
    "    clf = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"stack\", StackingClassifier(\n",
    "            estimators=base_models,\n",
    "            final_estimator=meta_model,\n",
    "            cv=5\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Fit and predict\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"Stacked Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return clf\n",
    "\n",
    "stacking_clf = stack_models(X,y, num_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42b715",
   "metadata": {},
   "source": [
    "#### Stacked Model Evaluation Summary\n",
    "\n",
    "- **Accuracy:** 0.57\n",
    "- **Class 0 (Majority Class):**\n",
    "  - Precision: 0.57  \n",
    "  - Recall: 0.77 (good at detecting Class 0)  \n",
    "  - F1-score: 0.66  \n",
    "\n",
    "- **Class 1 (Minority Class):**\n",
    "  - Precision: 0.56  \n",
    "  - Recall: 0.34 (poor detection of Class 1)  \n",
    "  - F1-score: 0.42  \n",
    "\n",
    "- **Overall Performance:**\n",
    "  - Macro Avg F1: 0.54 → balanced but modest performance.  \n",
    "  - Weighted Avg F1: 0.55 → slightly favors majority class.  \n",
    "  - Stacking improves stability but class imbalance remains an issue.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f0780",
   "metadata": {},
   "source": [
    "#### 2.33 We have got 0.56 accuracy we will try modified y_pred_proba to improve accuracy mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7385a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5951\n",
      "Best Threshold: 0.4597\n",
      "Accuracy: 0.5604140293394891\n",
      "F1 Score: 0.5548786005127432\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "y_proba = stacking_clf.predict_proba(X_test)[:, 1]  # prob for class=1\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Find best cutoff (Youden’s J statistic = maximize TPR - FPR)\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"Best Threshold: {best_thresh:.4f}\")\n",
    "\n",
    "# Apply threshold\n",
    "y_pred_opt = (y_proba >= best_thresh).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_opt))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_opt))\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.scatter(fpr[ix], tpr[ix], marker='o', color='red', label=\"Best threshold\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve (AUC={roc_auc:.4f})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcbfec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.45966102290815264\n",
      "Accuracy: 0.5604140293394891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.57    143875\n",
      "           1       0.52      0.59      0.55    124705\n",
      "\n",
      "    accuracy                           0.56    268580\n",
      "   macro avg       0.56      0.56      0.56    268580\n",
      "weighted avg       0.56      0.56      0.56    268580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_with_threshold(model, X_test, y_test, threshold=best_thresh):\n",
    "    # Get probabilities for class 1\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Apply threshold\n",
    "    y_pred = np.where(proba >= threshold, 1, 0)\n",
    "\n",
    "    # Metrics\n",
    "    print(f\"Threshold = {threshold}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "predict_with_threshold(stacking_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87a168",
   "metadata": {},
   "source": [
    "#### precision is low for class 1, lets try to achive above 0.6 with recall of +0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dc07d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.4\n",
      "Accuracy: 0.5221312085784496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.22      0.33    143875\n",
      "           1       0.49      0.87      0.63    124705\n",
      "\n",
      "    accuracy                           0.52    268580\n",
      "   macro avg       0.58      0.55      0.48    268580\n",
      "weighted avg       0.58      0.52      0.47    268580\n",
      "\n",
      "Threshold = 0.42000000000000004\n",
      "Accuracy: 0.5356653511058158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.30      0.41    143875\n",
      "           1       0.50      0.80      0.62    124705\n",
      "\n",
      "    accuracy                           0.54    268580\n",
      "   macro avg       0.57      0.55      0.51    268580\n",
      "weighted avg       0.58      0.54      0.51    268580\n",
      "\n",
      "Threshold = 0.44000000000000006\n",
      "Accuracy: 0.5488792910864547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.41      0.49    143875\n",
      "           1       0.51      0.71      0.59    124705\n",
      "\n",
      "    accuracy                           0.55    268580\n",
      "   macro avg       0.56      0.56      0.54    268580\n",
      "weighted avg       0.57      0.55      0.54    268580\n",
      "\n",
      "Threshold = 0.4600000000000001\n",
      "Accuracy: 0.5603842430560727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57    143875\n",
      "           1       0.52      0.59      0.55    124705\n",
      "\n",
      "    accuracy                           0.56    268580\n",
      "   macro avg       0.56      0.56      0.56    268580\n",
      "weighted avg       0.56      0.56      0.56    268580\n",
      "\n",
      "Threshold = 0.4800000000000001\n",
      "Accuracy: 0.567626033211706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62    143875\n",
      "           1       0.54      0.46      0.50    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.56      0.56      0.56    268580\n",
      "weighted avg       0.56      0.57      0.56    268580\n",
      "\n",
      "Threshold = 0.5000000000000001\n",
      "Accuracy: 0.570988159952342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.77      0.66    143875\n",
      "           1       0.56      0.34      0.42    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.57      0.56      0.54    268580\n",
      "weighted avg       0.57      0.57      0.55    268580\n",
      "\n",
      "Threshold = 0.5200000000000001\n",
      "Accuracy: 0.5698748976096507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.85      0.68    143875\n",
      "           1       0.59      0.25      0.35    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.58      0.55      0.51    268580\n",
      "weighted avg       0.58      0.57      0.52    268580\n",
      "\n",
      "Threshold = 0.5400000000000001\n",
      "Accuracy: 0.5670414773996575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69    143875\n",
      "           1       0.62      0.18      0.28    124705\n",
      "\n",
      "    accuracy                           0.57    268580\n",
      "   macro avg       0.59      0.54      0.48    268580\n",
      "weighted avg       0.59      0.57      0.50    268580\n",
      "\n",
      "Threshold = 0.5600000000000002\n",
      "Accuracy: 0.5643458187504654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70    143875\n",
      "           1       0.65      0.13      0.22    124705\n",
      "\n",
      "    accuracy                           0.56    268580\n",
      "   macro avg       0.60      0.54      0.46    268580\n",
      "weighted avg       0.60      0.56      0.48    268580\n",
      "\n",
      "Threshold = 0.5800000000000002\n",
      "Accuracy: 0.5616352669595651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70    143875\n",
      "           1       0.68      0.11      0.18    124705\n",
      "\n",
      "    accuracy                           0.56    268580\n",
      "   macro avg       0.62      0.53      0.44    268580\n",
      "weighted avg       0.61      0.56      0.46    268580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate values from 0.40 up to (but not including) 0.61, with a step of 0.2\n",
    "thresholds_values = np.arange(0.40, 0.60, 0.02)\n",
    "\n",
    "for thres in thresholds_values:\n",
    "    predict_with_threshold(stacking_clf, X_test, y_test, threshold=thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22072a36",
   "metadata": {},
   "source": [
    "#### Threshold Tuning Summary\n",
    "\n",
    "- **Threshold = 0.40**  \n",
    "  - Accuracy: 0.52  \n",
    "  - Class 0 → Precision: 0.66, Recall: 0.22, F1: 0.33  \n",
    "  - Class 1 → Precision: 0.49, Recall: 0.87, F1: 0.63  \n",
    "  - *Model strongly favors Class 1 (high recall), but poor detection of Class 0.*\n",
    "\n",
    "- **Threshold = 0.44**  \n",
    "  - Accuracy: 0.55  \n",
    "  - Class 0 → Precision: 0.62, Recall: 0.41, F1: 0.49  \n",
    "  - Class 1 → Precision: 0.51, Recall: 0.71, F1: 0.59  \n",
    "  - *Better balance, but still favors Class 1.*\n",
    "\n",
    "- **Threshold = 0.46**  \n",
    "  - Accuracy: 0.56  \n",
    "  - Class 0 → Precision: 0.60, Recall: 0.54, F1: 0.57  \n",
    "  - Class 1 → Precision: 0.52, Recall: 0.59, F1: 0.55  \n",
    "  - *Most balanced performance between classes.*\n",
    "\n",
    "- **Threshold = 0.48**  \n",
    "  - Accuracy: 0.57  \n",
    "  - Class 0 → Precision: 0.59, Recall: 0.66, F1: 0.62  \n",
    "  - Class 1 → Precision: 0.54, Recall: 0.46, F1: 0.50  \n",
    "  - *Slightly favors Class 0, but still relatively balanced.*\n",
    "\n",
    "- **Threshold = 0.50 (Default)**  \n",
    "  - Accuracy: 0.57  \n",
    "  - Class 0 → Precision: 0.57, Recall: 0.77, F1: 0.66  \n",
    "  - Class 1 → Precision: 0.56, Recall: 0.34, F1: 0.42  \n",
    "  - *Model starts to favor Class 0.*\n",
    "\n",
    "- **Threshold ≥ 0.52**  \n",
    "  - Accuracy remains ~0.56–0.57  \n",
    "  - Class 0 recall increases sharply (up to 0.97), but Class 1 recall drops (as low as 0.08)  \n",
    "  - *Severe imbalance toward Class 0 detection.*\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways:**  \n",
    "- **Threshold 0.40–0.44:** High recall for Class 1, poor for Class 0.  \n",
    "- **Threshold 0.46–0.48:** Best balance between precision and recall for both classes.  \n",
    "- **Threshold ≥ 0.50:** Model increasingly favors Class 0, with Class 1 recall dropping sharply.  \n",
    "- **Optimal threshold range:** **0.46–0.48** for balanced detection of both classes.  \n",
    "- **Overall:** Adjusting the threshold allows you to trade off between detecting more positives (Class 1) or negatives (Class 0), depending on your application’s needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
